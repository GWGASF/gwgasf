{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import ml4gw\n",
    "\n",
    "import numpy as np\n",
    "from ml4gw import gw\n",
    "from ml4gw import transforms \n",
    "from ml4gw.spectral import fast_spectral_density, spectral_density\n",
    "from ml4gw.transforms import SnrRescaler, Whiten\n",
    "from ml4gw.transforms.transform import FittableSpectralTransform\n",
    "from ml4gw.distributions import LogNormal, PowerLaw\n",
    "\n",
    "from gasf_data.utils import h5_thang\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predefined function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masking(\n",
    "    glitch_info: dict,\n",
    "    segment_duration: float,\n",
    "    segment_start_time: float=0,\n",
    "    shift_range: float = 3, \n",
    "    pad_width: float = 1.5, # Make this default to half of the kernel width\n",
    "    sample_rate: int=4096, \n",
    "    merge_edges: bool=True\n",
    ")->dict:\n",
    "    \n",
    "    \"\"\"Provide a buffer mask the covers the glitch at the center of the kernel.\n",
    "    \n",
    "\n",
    "    Args:\n",
    "        glitch_info (dict): Glitch trigger times by each detector.\n",
    "        segment_duration (float): Duration of the background.\n",
    "        segment_start_time (float): Start time of the background. Defaults to 0.\n",
    "        kernel_width (float, optional): The time width to cover a glitch signal.\n",
    "        The unit is second. Defaults to 3.\n",
    "        pad_width (float, optional)): \n",
    "        sample_rate (int, optional): The sampling rate of the background. Defaults to 4096.\n",
    "        merge_edges (bool, optional): If true it will autometically conbine glitch masks \n",
    "        if the two kernels overlap.\n",
    "\n",
    "    Returns:\n",
    "        dict: A mask that labes the idxs that covers all glitch and edges \n",
    "        by the kernel start idx and end idx for each detectors. \n",
    "    \"\"\"\n",
    "    \n",
    "    mask_kernel = {}\n",
    "    if pad_width < shift_range/2:\n",
    "        raise AttributeError(f\"pad_width {pad_width} is shorter than half of the kernel_width {shift_range/2}\")\n",
    "    \n",
    "    half_window = int(shift_range*sample_rate/2)\n",
    "    seg_idx_count = segment_duration*sample_rate\n",
    "    \n",
    "\n",
    "    \n",
    "    for ifo, glitch_time in glitch_info.items():\n",
    "        \n",
    "        # Initialing the first digits in the active segments aline to t0 = 0_sec\n",
    "        glitch_time -= segment_start_time\n",
    "        \n",
    "        # Pop out glitch that lives in the edges\n",
    "        ### This popping may need another argument passing.\n",
    "        glitch_time = glitch_time[glitch_time > pad_width]\n",
    "        glitch_time = glitch_time[glitch_time < segment_duration - pad_width]\n",
    "        \n",
    "        glitch_counts = len(glitch_time)\n",
    "        mask_kernel[ifo] = np.zeros((glitch_counts+2, 2)).astype(\"int\")\n",
    "        \n",
    "        # Provde the pad out edges mask\n",
    "        mask_kernel[ifo][0, :] = np.array([0, pad_width*sample_rate])\n",
    "        mask_kernel[ifo][-1, :] = np.array([seg_idx_count-pad_width*sample_rate, seg_idx_count])\n",
    "        \n",
    "        # Collecting the mask by idx\n",
    "        glitch_idx = (glitch_time * 4096).astype(\"int\")\n",
    "        \n",
    "        mask_kernel[ifo][1:-1, 0] = (glitch_idx - half_window)\n",
    "        mask_kernel[ifo][1:-1, 1] = (glitch_idx + half_window)\n",
    "        \n",
    "    \n",
    "    if merge_edges:\n",
    "        \n",
    "        for ifo, mask in mask_kernel.items():\n",
    "            \n",
    "            mask_counts = mask.shape[0]\n",
    "            for i in range(mask_counts -1 ):\n",
    "                \n",
    "                if mask[i,1] > mask[i+1,0]:\n",
    "                    mask[i,1] = mask[i+1,0]\n",
    "                    \n",
    "                    \n",
    "    return mask_kernel\n",
    "\n",
    "\n",
    "def filtering_idxs(\n",
    "    mask_dict: dict,\n",
    "    *n_idxs: int,\n",
    "    full: bool=False,\n",
    "):\n",
    "    \"\"\"Find segments that \n",
    "\n",
    "    Takes in the labeles \n",
    "    Args:\n",
    "        mask_dict (dict): _description_\n",
    "        segment_dur (float): _description_\n",
    "        kernel_width (int, optional): _description_. Defaults to 2.\n",
    "        sample_rate (int, optional): _description_. Defaults to 4096.\n",
    "        shuffle (bool, optional): _description_. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    idx_dict = {}\n",
    "    for ifo, mask in mask_dict.items():\n",
    "    \n",
    "        glitch_counts = len(mask)\n",
    "\n",
    "        sampling_idx = []\n",
    "\n",
    "        for i in range(glitch_counts-1):\n",
    "            \n",
    "            # Collecting usefull segments by its idx\n",
    "            sampling_idx.append(torch.arange(mask[i,1], mask[i+1,0]))\n",
    "            \n",
    "        collected_idx = torch.cat(sampling_idx)\n",
    "        \n",
    "        \n",
    "        if full:\n",
    "            \n",
    "            idx_dict[ifo] = collected_idx\n",
    "        \n",
    "            \n",
    "        sampling_idx = torch.randint(0, len(collected_idx), n_idxs)\n",
    "\n",
    "        idx_dict[ifo] = collected_idx[sampling_idx]\n",
    "    \n",
    "    return idx_dict\n",
    "\n",
    "\n",
    "def strain_sampling(\n",
    "    strain,\n",
    "    mask: dict,\n",
    "    sample_counts,\n",
    "    sample_rate = 4096,\n",
    "    kernel_width = 2,\n",
    "):\n",
    "\n",
    "    half_kernel_width_idx = int(kernel_width * sample_rate / 2)\n",
    "    \n",
    "    sampled_strain = torch.zeros([sample_counts, len(mask), sample_rate*kernel_width])\n",
    "\n",
    "    # Cosider remove this part out of the function\n",
    "    sampling_idx = filtering_idxs(\n",
    "        mask, \n",
    "        sample_counts,\n",
    "    )\n",
    "\n",
    "    for _ , idxs in sampling_idx.items():\n",
    "        for i, idx in enumerate(idxs):\n",
    "\n",
    "            sampled_strain[i,:,:] = strain[:, idx-half_kernel_width_idx:idx+half_kernel_width_idx]\n",
    "        \n",
    "    return sampled_strain\n",
    "\n",
    "\n",
    "def glitch_sampler(\n",
    "    glitch_info,\n",
    "    strain,\n",
    "    segment_duration,\n",
    "    segment_start_time,\n",
    "    ifos,\n",
    "    sample_counts,\n",
    "    sample_rate = 4096,\n",
    "    shift_range = 0.9,\n",
    "    kernel_width = 3,\n",
    "):\n",
    "    \n",
    "    half_kernel_width_idx = int(kernel_width * sample_rate / 2)\n",
    "    \n",
    "    sampled_strain = torch.zeros([sample_counts, len(ifos), sample_rate*kernel_width])\n",
    "\n",
    "    mask_dict = masking(\n",
    "        glitch_info,\n",
    "        segment_duration=segment_duration,\n",
    "        segment_start_time=segment_start_time,\n",
    "        shift_range=shift_range,\n",
    "        pad_width=kernel_width,\n",
    "        sample_rate=sample_rate, \n",
    "        merge_edges = False\n",
    "    )\n",
    "    \n",
    "    for i, ifo in enumerate(ifos):\n",
    "        \n",
    "        # Remove the padding mask\n",
    "        mask_dict[ifo] = mask_dict[ifo][1:-1]\n",
    "        \n",
    "        glitch_count = len(mask_dict[ifo])\n",
    "        # print(glitch_count)\n",
    "        selected_glitch = np.random.randint(0, glitch_count, (sample_counts,))\n",
    "        sample_center = np.random.randint(\n",
    "            mask_dict[ifo][selected_glitch][:, 0], \n",
    "            mask_dict[ifo][selected_glitch][:, 1], \n",
    "            size=(sample_counts)\n",
    "        )\n",
    "        \n",
    "        for j in range(sample_counts):\n",
    "            \n",
    "            start_idx = sample_center[j] - half_kernel_width_idx \n",
    "            end_idx = sample_center[j] + half_kernel_width_idx\n",
    "            # print(strain[i, start_idx: end_idx].shape)\n",
    "            sampled_strain[j, i, :] = strain[i, start_idx: end_idx]\n",
    "\n",
    "    return sampled_strain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Making"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CHANNLES = 2\n",
    "\n",
    "SAMPLE_RATE = 4096\n",
    "FFTLENGTH = 2\n",
    "OVERLAP = 1\n",
    "# BACKGROUND_DURATION = 36000\n",
    "BACKGROUND_DURATION = 4096\n",
    "KERNEL_WIDTH = 3\n",
    "WAVEFORM_DURATION = 3#8\n",
    "# WAVEFORM_DURATION = 3\n",
    "HIGHPASS = 32\n",
    "\n",
    "ITERATION = 10\n",
    "BATCH_SIZE = 1163\n",
    "# ITERATION = 20\n",
    "# BATCH_SIZE = 320\n",
    "\n",
    "MIN_SNR = 8\n",
    "MAX_SNR = 50\n",
    "ALPHA = 3\n",
    "SNR_DISTRO = PowerLaw(MIN_SNR, MAX_SNR, ALPHA)\n",
    "\n",
    "GPSSTARTTIME = 1262471488\n",
    "GPSENDTIME = 1262507488\n",
    "GPSTOTALTIME = GPSENDTIME-GPSSTARTTIME # SHOULD BE BACKGROUND_DURATION\n",
    "\n",
    "BACKGROUND_DURATION = GPSTOTALTIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some psudo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strain = torch.randn(NUM_CHANNLES, SAMPLE_RATE*BACKGROUND_DURATION)\n",
    "# signals = torch.randn(ITERATION*BATCH_SIZE, NUM_CHANNLES, SAMPLE_RATE*WAVEFORM_DURATION)\n",
    "\n",
    "# glitch_info = {\n",
    "#     'H1/time': np.sort(np.random.uniform(0+0.5, BACKGROUND_DURATION-0.5, 3046)), \n",
    "#     'L1/time': np.sort(np.random.uniform(0+0.5, BACKGROUND_DURATION-0.5, 3046))\n",
    "# }\n",
    "\n",
    "\n",
    "# signals.shape\n",
    "# strain.shape\n",
    "\n",
    "\n",
    "# glitch_idx_h1 = (glitch_info['H1/time']*SAMPLE_RATE).astype(\"int\")\n",
    "# glitch_idx_l1 = (glitch_info['L1/time']*SAMPLE_RATE).astype(\"int\")\n",
    "   \n",
    "# GPSSTARTTIME = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some Real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filenames\n",
    "\n",
    "signalsFilename = '/home/dfredin/gwgasf/data/BBH_project.h5'\n",
    "\n",
    "\n",
    "H1strainFilename_1 = '/home/dfredin/gwgasf/data/H1/H-H1_GWOSC_O3b_4KHZ_R1-1262469120-4096.hdf5'\n",
    "H1strainFilename_2 = '/home/dfredin/gwgasf/data/H1/H-H1_GWOSC_O3b_4KHZ_R1-1262473216-4096.hdf5'\n",
    "H1strainFilename_3 = '/home/dfredin/gwgasf/data/H1/H-H1_GWOSC_O3b_4KHZ_R1-1262477312-4096.hdf5'\n",
    "H1strainFilename_4 = '/home/dfredin/gwgasf/data/H1/H-H1_GWOSC_O3b_4KHZ_R1-1262481408-4096.hdf5'\n",
    "H1strainFilename_5 = '/home/dfredin/gwgasf/data/H1/H-H1_GWOSC_O3b_4KHZ_R1-1262485504-4096.hdf5'\n",
    "H1strainFilename_6 = '/home/dfredin/gwgasf/data/H1/H-H1_GWOSC_O3b_4KHZ_R1-1262489600-4096.hdf5'\n",
    "H1strainFilename_7 = '/home/dfredin/gwgasf/data/H1/H-H1_GWOSC_O3b_4KHZ_R1-1262493696-4096.hdf5'\n",
    "H1strainFilename_8 = '/home/dfredin/gwgasf/data/H1/H-H1_GWOSC_O3b_4KHZ_R1-1262497792-4096.hdf5'\n",
    "H1strainFilename_9 = '/home/dfredin/gwgasf/data/H1/H-H1_GWOSC_O3b_4KHZ_R1-1262501888-4096.hdf5'\n",
    "H1strainFilename_10 ='/home/dfredin/gwgasf/data/H1/H-H1_GWOSC_O3b_4KHZ_R1-1262505984-4096.hdf5'\n",
    "\n",
    "L1strainFilename_1 = '/home/dfredin/gwgasf/data/L1/L-L1_GWOSC_O3b_4KHZ_R1-1262469120-4096.hdf5'\n",
    "L1strainFilename_2 = '/home/dfredin/gwgasf/data/L1/L-L1_GWOSC_O3b_4KHZ_R1-1262473216-4096.hdf5'\n",
    "L1strainFilename_3 = '/home/dfredin/gwgasf/data/L1/L-L1_GWOSC_O3b_4KHZ_R1-1262477312-4096.hdf5'\n",
    "L1strainFilename_4 = '/home/dfredin/gwgasf/data/L1/L-L1_GWOSC_O3b_4KHZ_R1-1262481408-4096.hdf5'\n",
    "L1strainFilename_5 = '/home/dfredin/gwgasf/data/L1/L-L1_GWOSC_O3b_4KHZ_R1-1262485504-4096.hdf5'\n",
    "L1strainFilename_6 = '/home/dfredin/gwgasf/data/L1/L-L1_GWOSC_O3b_4KHZ_R1-1262489600-4096.hdf5'\n",
    "L1strainFilename_7 = '/home/dfredin/gwgasf/data/L1/L-L1_GWOSC_O3b_4KHZ_R1-1262493696-4096.hdf5'\n",
    "L1strainFilename_8 = '/home/dfredin/gwgasf/data/L1/L-L1_GWOSC_O3b_4KHZ_R1-1262497792-4096.hdf5'\n",
    "L1strainFilename_9 = '/home/dfredin/gwgasf/data/L1/L-L1_GWOSC_O3b_4KHZ_R1-1262501888-4096.hdf5'\n",
    "L1strainFilename_10 ='/home/dfredin/gwgasf/data/L1/L-L1_GWOSC_O3b_4KHZ_R1-1262505984-4096.hdf5'\n",
    "\n",
    "\n",
    "glitchFilename = '/home/dfredin/gwgasf/data/glitch_info.h5'\n",
    "\n",
    "\n",
    "# BBH Signals\n",
    "\n",
    "signal_info = h5_thang(signalsFilename).h5_data()\n",
    "signal_keys = list(signal_info.keys())\n",
    "\n",
    "signal_bbh_H1 = signal_info['waveforms_H1']\n",
    "signal_bbh_L1 = signal_info['waveforms_L1']\n",
    "\n",
    "signals = torch.FloatTensor(np.stack([signal_bbh_H1, signal_bbh_L1], axis=1))\n",
    "del signal_bbh_H1, signal_bbh_L1\n",
    "\n",
    "signals.shape\n",
    "\n",
    "\n",
    "\n",
    "# LIGO Strain\n",
    "strain_keys = h5_thang(H1strainFilename_1).h5_keys()\n",
    "\n",
    "# H1 strain\n",
    "H1strain_info_1 = h5_thang(H1strainFilename_1).h5_data()\n",
    "H1strain_1 = np.array(H1strain_info_1['strain/Strain'])\n",
    "\n",
    "H1strain_info_2 = h5_thang(H1strainFilename_2).h5_data()\n",
    "H1strain_2 = np.array(H1strain_info_2['strain/Strain'])\n",
    "\n",
    "H1strain_info_3 = h5_thang(H1strainFilename_3).h5_data()\n",
    "H1strain_3 = np.array(H1strain_info_3['strain/Strain'])\n",
    "\n",
    "H1strain_info_4 = h5_thang(H1strainFilename_4).h5_data()\n",
    "H1strain_4 = np.array(H1strain_info_4['strain/Strain'])\n",
    "\n",
    "H1strain_info_5 = h5_thang(H1strainFilename_5).h5_data()\n",
    "H1strain_5 = np.array(H1strain_info_5['strain/Strain'])\n",
    "\n",
    "H1strain_info_6 = h5_thang(H1strainFilename_6).h5_data()\n",
    "H1strain_6 = np.array(H1strain_info_6['strain/Strain'])\n",
    "\n",
    "H1strain_info_7 = h5_thang(H1strainFilename_7).h5_data()\n",
    "H1strain_7 = np.array(H1strain_info_7['strain/Strain'])\n",
    "\n",
    "H1strain_info_8 = h5_thang(H1strainFilename_8).h5_data()\n",
    "H1strain_8 = np.array(H1strain_info_8['strain/Strain'])\n",
    "\n",
    "H1strain_info_9 = h5_thang(H1strainFilename_9).h5_data()\n",
    "H1strain_9 = np.array(H1strain_info_9['strain/Strain'])\n",
    "\n",
    "H1strain_info_10 = h5_thang(H1strainFilename_10).h5_data()\n",
    "H1strain_10 = np.array(H1strain_info_10['strain/Strain'])\n",
    "\n",
    "# L1 strain\n",
    "L1strain_info_1 = h5_thang(L1strainFilename_1).h5_data()\n",
    "L1strain_1 = np.array(L1strain_info_1['strain/Strain'])\n",
    "\n",
    "L1strain_info_2 = h5_thang(L1strainFilename_2).h5_data()\n",
    "L1strain_2 = np.array(L1strain_info_2['strain/Strain'])\n",
    "\n",
    "L1strain_info_3 = h5_thang(L1strainFilename_3).h5_data()\n",
    "L1strain_3 = np.array(L1strain_info_3['strain/Strain'])\n",
    "\n",
    "L1strain_info_4 = h5_thang(L1strainFilename_4).h5_data()\n",
    "L1strain_4 = np.array(L1strain_info_4['strain/Strain'])\n",
    "\n",
    "L1strain_info_5 = h5_thang(L1strainFilename_5).h5_data()\n",
    "L1strain_5 = np.array(L1strain_info_5['strain/Strain'])\n",
    "\n",
    "L1strain_info_6 = h5_thang(L1strainFilename_6).h5_data()\n",
    "L1strain_6 = np.array(L1strain_info_6['strain/Strain'])\n",
    "\n",
    "L1strain_info_7 = h5_thang(L1strainFilename_7).h5_data()\n",
    "L1strain_7 = np.array(L1strain_info_7['strain/Strain'])\n",
    "\n",
    "L1strain_info_8 = h5_thang(L1strainFilename_8).h5_data()\n",
    "L1strain_8 = np.array(L1strain_info_8['strain/Strain'])\n",
    "\n",
    "L1strain_info_9 = h5_thang(L1strainFilename_9).h5_data()\n",
    "L1strain_9 = np.array(L1strain_info_9['strain/Strain'])\n",
    "\n",
    "L1strain_info_10 = h5_thang(L1strainFilename_10).h5_data()\n",
    "L1strain_10 = np.array(L1strain_info_10['strain/Strain'])\n",
    "\n",
    "\n",
    "h1strain = np.concatenate([H1strain_1, H1strain_2, H1strain_3, H1strain_4, H1strain_5, H1strain_6, H1strain_7, H1strain_8, H1strain_9, H1strain_10])\n",
    "l1strain = np.concatenate([L1strain_1, L1strain_2, L1strain_3, L1strain_4, L1strain_5, L1strain_6, L1strain_7, L1strain_8, L1strain_9, L1strain_10])\n",
    "\n",
    "del H1strain_1, H1strain_2, H1strain_3, H1strain_4, H1strain_5, H1strain_6, H1strain_7, H1strain_8, H1strain_9, H1strain_10\n",
    "del L1strain_1, L1strain_2, L1strain_3, L1strain_4, L1strain_5, L1strain_6, L1strain_7, L1strain_8, L1strain_9, L1strain_10\n",
    "\n",
    "strain = torch.FloatTensor(np.stack([h1strain, l1strain], axis=0))\n",
    "\n",
    "del h1strain, l1strain\n",
    "\n",
    "strain.shape\n",
    "\n",
    "\n",
    "# Glitches\n",
    "glitch_list = 'H1/time','L1/time'\n",
    "glitch_info = h5_thang(glitchFilename).h5_data(glitch_list)\n",
    "glitch_keys = h5_thang(glitchFilename).h5_keys()\n",
    "\n",
    "glitchGPStime_h1 = np.array(glitch_info['H1/time'])\n",
    "glitchGPStime_l1 = np.array(glitch_info['L1/time'])\n",
    "\n",
    "\n",
    "glitch_idx_h1 = (((glitchGPStime_h1-GPSSTARTTIME)/36000)*SAMPLE_RATE*SAMPLE_RATE).astype(\"int\")\n",
    "glitch_idx_l1 = (((glitchGPStime_l1[0:3046]-GPSSTARTTIME)/36000)*SAMPLE_RATE*SAMPLE_RATE).astype(\"int\")\n",
    "\n",
    "del glitchGPStime_h1, glitchGPStime_l1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_glitch_idx_span = 2048 ##????\n",
    "glitch_amp = 3\n",
    "\n",
    "contaminated_strain = strain\n",
    "\n",
    "for pulse in glitch_idx_h1:\n",
    "    contaminated_strain[0, (pulse-half_glitch_idx_span):pulse+half_glitch_idx_span] += glitch_amp*torch.randn((2*half_glitch_idx_span))\n",
    "    \n",
    "for pulse in glitch_idx_l1:\n",
    "    contaminated_strain[1, (pulse-half_glitch_idx_span):pulse+half_glitch_idx_span] += glitch_amp*torch.randn((2*half_glitch_idx_span))\n",
    "    \n",
    "    \n",
    "del glitch_idx_h1, glitch_idx_l1, strain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precauculate_PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This is served for more detailed control \n",
    "# spec_trans = FittableSpectralTransform()\n",
    "\n",
    "# psds = torch.empty([NUM_CHANNLES, int((SAMPLE_RATE*KERNEL_WIDTH)/2) +1])\n",
    "\n",
    "# psds[0, :] = spec_trans.normalize_psd(\n",
    "#     contaminated_strain[0],\n",
    "#     sample_rate=SAMPLE_RATE,\n",
    "#     num_freqs=int((SAMPLE_RATE*KERNEL_WIDTH)/2) +1,\n",
    "#     fftlength=FFTLENGTH,\n",
    "#     overlap=OVERLAP,\n",
    "# )\n",
    "\n",
    "# psds[1, :] = spec_trans.normalize_psd(\n",
    "#     contaminated_strain[1],\n",
    "#     sample_rate=SAMPLE_RATE,\n",
    "#     num_freqs=int((SAMPLE_RATE*KERNEL_WIDTH)/2) +1,\n",
    "#     fftlength=FFTLENGTH,\n",
    "#     overlap=OVERLAP,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling BG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Background\n",
    "\n",
    "mask_dict = masking(\n",
    "    glitch_info,\n",
    "    segment_duration=BACKGROUND_DURATION,\n",
    "    shift_range=KERNEL_WIDTH,\n",
    "    pad_width=KERNEL_WIDTH/2,\n",
    "    merge_edges = True\n",
    ")\n",
    "\n",
    "background = strain_sampling(\n",
    "    contaminated_strain,\n",
    "    mask_dict,\n",
    "    sample_counts=ITERATION*BATCH_SIZE,\n",
    "    kernel_width=KERNEL_WIDTH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling Glitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glitch data\n",
    "\n",
    "glitches = glitch_sampler(\n",
    "    glitch_info=glitch_info,\n",
    "    strain = contaminated_strain,\n",
    "    segment_duration = BACKGROUND_DURATION,\n",
    "    segment_start_time = GPSSTARTTIME,\n",
    "    ifos = ['H1/time', 'L1/time'],\n",
    "    sample_counts = ITERATION*BATCH_SIZE,\n",
    "    sample_rate = SAMPLE_RATE,\n",
    "    shift_range = 0.9,\n",
    "    kernel_width = 3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling Injections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Injection\n",
    "\n",
    "mask_dict = masking(\n",
    "    glitch_info,\n",
    "    segment_duration=BACKGROUND_DURATION,\n",
    "    shift_range=KERNEL_WIDTH,\n",
    "    pad_width=KERNEL_WIDTH/2,\n",
    "    merge_edges = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "####\n",
    "sampled_bg = strain_sampling(\n",
    "    contaminated_strain,\n",
    "    mask_dict,\n",
    "    sample_counts=ITERATION*BATCH_SIZE,\n",
    "    kernel_width=KERNEL_WIDTH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalizing some class\n",
    "\n",
    "rescaler = SnrRescaler(\n",
    "    num_channels=NUM_CHANNLES, \n",
    "    sample_rate = SAMPLE_RATE,\n",
    "    waveform_duration = WAVEFORM_DURATION,\n",
    "    highpass = HIGHPASS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "rescaler.fit(\n",
    "    contaminated_strain[0],\n",
    "    contaminated_strain[1],\n",
    "    fftlength=FFTLENGTH,\n",
    "    overlap=OVERLAP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaled_signals, target_snrs = rescaler.forward(\n",
    "    signals,\n",
    "    target_snrs=SNR_DISTRO(BATCH_SIZE*ITERATION)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "injection = sampled_bg + rescaled_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Injection\n",
    "\n",
    "# mask_dict = masking(\n",
    "#     glitch_info,\n",
    "#     segment_duration=BACKGROUND_DURATION,\n",
    "#     shift_range=KERNEL_WIDTH,\n",
    "#     pad_width=KERNEL_WIDTH/2,\n",
    "#     merge_edges = True\n",
    "# )\n",
    "\n",
    "# sampled_bg = strain_sampling(\n",
    "#     contaminated_strain,\n",
    "#     mask_dict,\n",
    "#     sample_counts=ITERATION*BATCH_SIZE,\n",
    "#     kernel_width=KERNEL_WIDTH\n",
    "# )\n",
    "\n",
    "# # Initalizing some class\n",
    "\n",
    "# rescaler = SnrRescaler(\n",
    "#     num_channels=NUM_CHANNLES, \n",
    "#     sample_rate = SAMPLE_RATE,\n",
    "#     waveform_duration = WAVEFORM_DURATION,\n",
    "#     highpass = HIGHPASS,\n",
    "# )\n",
    "\n",
    "# rescaler.fit(\n",
    "#     contaminated_strain[0, :],\n",
    "#     contaminated_strain[1, :],\n",
    "#     fftlength=FFTLENGTH,\n",
    "#     overlap=OVERLAP\n",
    "# )\n",
    "\n",
    "# rescaled_signals, target_snrs = rescaler.forward(\n",
    "#     signals,\n",
    "#     target_snrs=SNR_DISTRO(BATCH_SIZE*ITERATION)\n",
    "# )\n",
    "\n",
    "# injection = sampled_bg + rescaled_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whiten_model = Whiten(\n",
    "    FFTLENGTH,\n",
    "    SAMPLE_RATE,\n",
    "    HIGHPASS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_data = whiten_model(\n",
    "    background, \n",
    "    psds\n",
    ")\n",
    "\n",
    "injected_data = whiten_model(\n",
    "    injection,\n",
    "    psds\n",
    ")\n",
    "\n",
    "glitch_data = whiten_model(\n",
    "    glitches,\n",
    "    psds\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_data.shape, injected_data.shape, glitch_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccsnet-train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
