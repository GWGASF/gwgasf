{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unraveling Gravitational Ripples: Neural Network Classification\n",
    "### GASF vs FFT vs QTransform with New Data\n",
    "### **GWGASF Members:** $Daniel\\;Fredin^{1,2}$, $Cole\\;Welch^{1,3}$, $Chia-Jui\\;Chou^{4}$, $Andy\\;Chen^{4}$, & $Shih-Chieh\\;Hsu^{1}$\n",
    "#### $^{1}University\\;of\\;Washington,\\;Seattle\\;USA$; $^{2}University\\;of\\;Massachusetts\\;Lowell,\\;Lowell\\;USA$;$^{3}Georgia\\;Institute\\;of\\;Technology,\\;Atlanta\\;USA$; $^{4}National\\;Yang\\;Ming\\;Chiao\\;Tung\\;University,\\;Hsinchu\\;City,\\;TW$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from pyts.image import GramianAngularField\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "\n",
    "from gasf.utils import h5_thang\n",
    "# import random\n",
    "\n",
    "# import h5py as h5\n",
    "# from gasf.sampling import # Finish module import\n",
    "# import ml4gw\n",
    "\n",
    "# Initializes numpy and pytorch random seeds for reproducibility \n",
    "seed = 55\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### need to modularize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ------------- Load dataset ------------- ###\n",
    "\n",
    "\n",
    "# Loading datafiles and only load a slice of the total data.\n",
    "numSamples = 1200 # from each glitch/signal/background\n",
    "\n",
    "# bbh signals\n",
    "bbh_signals_filename = '/home/dfredin/gwgasf/data/raw_data/bbh_dataset_p1.hdf5'\n",
    "bbh_info = h5_thang(bbh_signals_filename)\n",
    "bbh_keys = bbh_info.h5_keys()\n",
    "H1_bbh = bbh_info.h5_data()['H1'][0:numSamples]\n",
    "L1_bbh = bbh_info.h5_data()['L1'][0:numSamples]\n",
    "\n",
    "# H1 background\n",
    "H1_bg_filename = '/home/dfredin/gwgasf/data/raw_data/H1_bg_dataset_p1.hdf5'\n",
    "H1_bg_info = h5_thang(H1_bg_filename)\n",
    "H1_bg_keys = H1_bg_info.h5_keys()\n",
    "H1_bg = H1_bg_info.h5_data()['background_noise'][0:numSamples]\n",
    "# L1 background\n",
    "L1_bg_filename = '/home/dfredin/gwgasf/data/raw_data/L1_bg_dataset_p1.hdf5'\n",
    "L1_bg_info = h5_thang(L1_bg_filename)\n",
    "L1_bg_keys = L1_bg_info.h5_keys()\n",
    "L1_bg = L1_bg_info.h5_data()['background_noise'][0:numSamples]\n",
    "\n",
    "# H1 glitch\n",
    "H1_glitch_filename = '/home/dfredin/gwgasf/data/raw_data/H1_glitch_dataset_p1.hdf5'\n",
    "H1_glitch_info = h5_thang(H1_glitch_filename)\n",
    "H1_glitch_keys = H1_glitch_info.h5_keys()\n",
    "H1_glitch = H1_glitch_info.h5_data()['glitch'][0:numSamples]\n",
    "# L1 glitch\n",
    "L1_glitch_filename = '/home/dfredin/gwgasf/data/raw_data/L1_glitch_dataset_p1.hdf5'\n",
    "L1_glitch_info = h5_thang(L1_glitch_filename)\n",
    "L1_glitch_keys = L1_glitch_info.h5_keys()\n",
    "L1_glitch = L1_glitch_info.h5_data()['glitch'][0:numSamples]\n",
    "\n",
    "# # hfsg signals\n",
    "# hfsg_signals_filename = '/home/dfredin/gwgasf/data/raw_data/hfsg_dataset_p1.hdf5'\n",
    "# hfsg_info = h5_thang(hfsg_signals_filename)\n",
    "# hfsg_keys = hfsg_info.h5_keys()\n",
    "# H1_hfsg = hfsg_info.h5_data()['H1'][0:numSamples]\n",
    "# L1_hfsg = hfsg_info.h5_data()['L1'][0:numSamples]\n",
    "# # lfsg signals\n",
    "# lfsg_signals_filename = '/home/dfredin/gwgasf/data/raw_data/lfsg_dataset_p1.hdf5'\n",
    "# lfsg_info = h5_thang(lfsg_signals_filename)\n",
    "# lfsg_keys = lfsg_info.h5_keys()\n",
    "# H1_lfsg = lfsg_info.h5_data()['H1'][0:numSamples]\n",
    "# L1_lfsg = lfsg_info.h5_data()['L1'][0:numSamples]\n",
    "\n",
    "# variables = [H1_bbh, L1_bbh, H1_bg, H1_glitch, L1_bg, L1_glitch, H1_hfsg, L1_hfsg, H1_lfsg, L1_lfsg]\n",
    "# names = ['H1 BBH', 'L1 BBH', 'H1 BG', 'H1 Glitch', 'L1 BG', 'L1 Glitch', 'H1 HFSG', 'L1 HFSG', 'H1 LFSG', 'L1 LFSG']\n",
    "\n",
    "# for name, var in zip(names, variables):\n",
    "#     print(f\"{name} Shape: {var.shape}\")\n",
    "\n",
    "variables = [H1_bbh, L1_bbh, H1_bg, H1_glitch, L1_bg, L1_glitch]\n",
    "names = ['H1 BBH', 'L1 BBH', 'H1 BG', 'H1 Glitch', 'L1 BG', 'L1 Glitch']\n",
    "\n",
    "for name, var in zip(names, variables):\n",
    "    print(f\"{name} Shape: {var.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ------------- HIGH SNR GLITCH ------------- ###\n",
    "\n",
    "# This code block filters glitch signals based on their signal-to-noise ratio (SNR) \n",
    "H1_glitch_snr = H1_glitch_info.h5_data()['glitch_info']\n",
    "L1_glitch_snr = L1_glitch_info.h5_data()['glitch_info']\n",
    "\n",
    "# Filter glitch signals with SNR >= 10 for H1 detector\n",
    "h1_indices = np.where(H1_glitch_snr['snr'] >= 15)\n",
    "H1_glitch_snr_high = H1_glitch_info.h5_data()['glitch'][h1_indices]\n",
    "\n",
    "# Filter glitch signals with SNR >= 10 for L1 detector\n",
    "l1_indices = np.where(L1_glitch_snr['snr'] >= 15)\n",
    "L1_glitch_snr_high = L1_glitch_info.h5_data()['glitch'][l1_indices]\n",
    "\n",
    "# Truncate the glitch signals to have the same length\n",
    "H1_glitch_snr_high = H1_glitch_snr_high[0:len(L1_glitch_snr_high)]\n",
    "L1_glitch_snr_high = L1_glitch_snr_high[0:len(L1_glitch_snr_high)]\n",
    "\n",
    "# Create a stack of high SNR glitch signals from both detectors\n",
    "glitch_highsnr_signals = np.dstack((H1_glitch_snr_high, L1_glitch_snr_high))\n",
    "\n",
    "# Assign the stack of glitch signals to the final variable\n",
    "glitch_signals = glitch_highsnr_signals\n",
    "\n",
    "# Clean up variables to free up memory\n",
    "del L1_glitch_snr_high, H1_glitch_snr_high, H1_glitch_snr, L1_glitch_snr, glitch_highsnr_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ------------- STACK ARRAYS ------------- ###\n",
    "\n",
    "## Stacking the arrays for the H1 and L1 detectors\n",
    "\n",
    "bbh_signals = np.dstack((H1_bbh, L1_bbh))\n",
    "bg_signals = np.dstack((H1_bg, L1_bg))\n",
    "# TODO: Add the other high SNR glitches\n",
    "# glitch_signals = np.dstack((H1_glitch, L1_glitch))\n",
    "# hfsg_signals = np.dstack((H1_hfsg, L1_hfsg))\n",
    "# lfsg_signals = np.dstack((H1_lfsg, L1_lfsg))\n",
    "\n",
    "del H1_bbh, L1_bbh, H1_bg, L1_bg, H1_glitch, L1_glitch\n",
    "\n",
    "# variables = [bbh_signals, bg_signals, glitch_signals, hfsg_signals, lfsg_signals]\n",
    "# names = ['BBH Signals', 'BG Signals', 'Glitch Signals', 'HFSG Signals', 'LFSG Signals']\n",
    "\n",
    "# for name, var in zip(names, variables):\n",
    "#     print(f\"{name} Shape: {var.shape}\")\n",
    "\n",
    "x_train = np.concatenate((glitch_signals, bbh_signals, bg_signals))\n",
    "x_train.shape\n",
    "# x_train = np.concatenate((glitch_train, bbh_train, overlap_train), axis=0).transpose((0,2,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ---------------- ONE-HOT ENCODING ----------------------------##\n",
    "\n",
    "# NOTE: \n",
    "# Multiclassifier\n",
    "anomaly_class = {\n",
    "    'Glitch': [1, 0, 0],\n",
    "    'Signal': [0, 1, 0],\n",
    "    'Background': [0, 0, 1]\n",
    "}\n",
    "\n",
    "glitch_train_ids = np.full((glitch_signals.shape[0], 3), anomaly_class['Glitch'])\n",
    "bbh_train_ids = np.full((bbh_signals.shape[0], 3), anomaly_class['Signal'])\n",
    "bg_train_ids = np.full((bg_signals.shape[0], 3), anomaly_class['Background'])\n",
    "\n",
    "\n",
    "y_train_ids = np.concatenate((glitch_train_ids, bbh_train_ids, bg_train_ids), axis=0)\n",
    "del bbh_signals, bg_signals, glitch_signals\n",
    "del glitch_train_ids, bbh_train_ids, bg_train_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 1000\n",
    "\n",
    "# Generate the idx_train, idx_val to randomly sample from the training set and validation set.\n",
    "idx_train = np.random.randint(0, len(x_train), size=n_train)\n",
    "\n",
    "y_train = y_train_ids[idx_train]\n",
    "\n",
    "### ------------- GASF CONVERSION ------------- ###\n",
    "\n",
    "GASF = GramianAngularField(image_size=194, sample_range = (-1,1), method=\"summation\")\n",
    "# Convert training data to image format\n",
    "img_x_train_dec1 = GASF.transform(x_train[idx_train,:,0])\n",
    "img_x_train_dec2 = GASF.transform(x_train[idx_train,:,1])\n",
    "\n",
    "img_x_train = np.stack((img_x_train_dec1, img_x_train_dec2), axis=1)\n",
    "del img_x_train_dec1, img_x_train_dec2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ------------- Split into training and validation datasets ------------- ###\n",
    "\n",
    "# Assuming img_x_train is defined and has the shape (N, 2, 194, 194)\n",
    "# Assuming y_train is defined and has the shape (N, 3), where N can be any integer\n",
    "\n",
    "# Total number of samples\n",
    "total_samples = img_x_train.shape[0]\n",
    "\n",
    "# Calculate the number of samples in each dataset\n",
    "## NOTE: MAYBE USER INPUT FOR SPLIT %???\n",
    "num_train = int(0.8 * total_samples)  # 80% for training\n",
    "num_test = int(0.15 * total_samples)  # 15% for testing\n",
    "num_val = total_samples - num_train - num_test  # Remaining 5% for validation, adjusted to avoid rounding issues\n",
    "\n",
    "# Create training, testing, and validation datasets for img_x_train\n",
    "x_train_data = img_x_train[:num_train]\n",
    "x_test_data = img_x_train[num_train:num_train + num_test]\n",
    "x_val_data = img_x_train[num_train + num_test:]\n",
    "\n",
    "# Create training, testing, and validation datasets for y_train\n",
    "y_train_data = y_train[:num_train]\n",
    "y_test_data = y_train[num_train:num_train + num_test]\n",
    "y_val_data = y_train[num_train + num_test:]\n",
    "\n",
    "# Print shapes to verify the distribution\n",
    "strains = [x_train_data, x_test_data, x_val_data]\n",
    "targets = [y_train_data, y_test_data, y_val_data]\n",
    "labels = ['Training', 'Testing', 'Validation']\n",
    "\n",
    "# Collecting and printing the shape of each array\n",
    "array_shapes = [arr.shape for arr in strains]\n",
    "for i, shape in enumerate(array_shapes):\n",
    "    print(f\"{labels[i]} Data Shape: {shape}\")\n",
    "\n",
    "array_shapes = [arr.shape for arr in targets]\n",
    "for i, shape in enumerate(array_shapes):\n",
    "    print(f\"{labels[i]} Targets Shape: {shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glitch Plot\n",
    "\n",
    "y_train_label = str(y_train[0])\n",
    "# Create a new figure for the glitch plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x_train[idx_train, :, 0][0])  # Adjusted the indexing based on typical data structure\n",
    "plt.title(f'Label: {y_train_label}')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.show()\n",
    "\n",
    "# Create a new figure for the glitch GASF plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(img_x_train[:,0,:,:][0], cmap='rainbow', origin='lower')\n",
    "plt.title(f'Label: {y_train_label}')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Signal Plot\n",
    "\n",
    "y_train_label = str(y_train[548])\n",
    "# Create a new figure for the signal plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x_train[idx_train,:,0][548])\n",
    "plt.title(f'Label: {y_train_label}')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.show()\n",
    "\n",
    "# Create a new figure for the signal GASF plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(img_x_train[:,0,:,:][548], cmap='rainbow', origin='lower')\n",
    "plt.title(f'Label: {y_train_label}')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Background Plot\n",
    "\n",
    "y_train_label = str(y_train[55])\n",
    "# Create a new figure for the Background plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x_train[idx_train,:,0][55])\n",
    "plt.title(f'Label: {y_train_label}')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.show()\n",
    "\n",
    "# Create a new figure for the Background GASF plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(img_x_train[:,0,:,:][55], cmap='rainbow', origin='lower')\n",
    "plt.title(f'Label: {y_train_label}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, target, ifos=3, kernel_size=4096):\n",
    "\n",
    "        # Get data type from https://pytorch.org/docs/stable/tensors.html\n",
    "        # self.data = torch.FloatTensor(\n",
    "        #     data.reshape([-1, ifos, kernel_size])\n",
    "        # )\n",
    "        # \n",
    "        self.data = torch.FloatTensor(data)\n",
    "        self.targets = torch.FloatTensor(target)\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.data)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.targets[index]\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Training data into pytorch tensor\n",
    "dataset = MyDataset(strains[0], targets[0])\n",
    "training_data = DataLoader(\n",
    "    dataset, \n",
    "    batch_size=32, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Load testing data into pytorch tensor\n",
    "dataset_t = MyDataset(strains[2], targets[2])\n",
    "testing_data = DataLoader(\n",
    "    dataset_t, \n",
    "    batch_size=32, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "# Load Validation data into pytorch tensor\n",
    "dataset_v = MyDataset(strains[1], targets[1])\n",
    "validation_data = DataLoader(\n",
    "    dataset_v, \n",
    "    batch_size=32, \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strains[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "               ## # | 64 x 64 | 127 x 127 | 194 x 194 |\n",
    "cnn1In = 2     ## # |    2    |     2     |     2     |\n",
    "cnn1Out = 64   ## # |    16   |     16    |     16    |    \n",
    "cnn1K = 6      ## # |    4    |     5     |     6     |\n",
    "cnn1S = 2      ## # |    2    |     2     |     2     |\n",
    "cnn1P = 1      ## # |    1    |     2     |     1     |\n",
    "batch1 = 64    ## # |    16   |     16    |     16    |\n",
    "max1K = 5      ## # |    4    |     2     |     5     |\n",
    "max1S = 3      ## # |    2    |     2     |     3     |\n",
    "max1P = 1      ## # |    1    |     0     |     1     |\n",
    "\n",
    "cnn2In = 64    ## # |    16   |     16    |     16    |\n",
    "cnn2Out = 128   ## # |    32   |     32    |     32    |\n",
    "cnn2K = 4      ## # |    3    |     4     |     4     |\n",
    "cnn2S = 2      ## # |    1    |     2     |     2     |\n",
    "cnn2P = 1      ## # |    1    |     1     |     1     |\n",
    "batch2 = 128    ## # |    32   |     32    |     32    |\n",
    "max2K = 2      ## # |    2    |     2     |     2     |\n",
    "max2S = 2      ## # |    2    |     2     |     2     |\n",
    "max2P = 0      ## # |    0    |     0     |     0     |\n",
    "\n",
    "### -------------194 x 194 Model Definition------------- ###\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(CNNModel, self).__init__()\n",
    "\n",
    "                # First convolution layer (2 channel -> 16 channels, preserve original dimension by adding padding = 2) \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=2, out_channels=cnn1Out, kernel_size=cnn1K, stride=cnn1S, padding=cnn1P),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(batch1),\n",
    "            nn.MaxPool2d(kernel_size=max1K, stride=max1S, padding=max1P)\n",
    "            )\n",
    "        \n",
    "        # Second convolution layer (16 channel -> 32 channels, preserve dimension by adding padding = 2)\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=cnn2In, out_channels=cnn2Out, kernel_size=cnn2K, stride=cnn2S, padding=cnn2P),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(batch2),\n",
    "            nn.MaxPool2d(kernel_size=max2K, stride=max2S, padding=max2P)\n",
    "            )\n",
    "\n",
    "        # Fully connected layer that takes the flattened output of layer 2 (32, 8 ,8) -> (2048) and output 2 classes\n",
    "        self.fc1 = nn.Linear(in_features=128*8*8, out_features=1024)\n",
    "        self.fc2 = nn.Linear(in_features=1024, out_features=512)\n",
    "        self.fc3 = nn.Linear(in_features=512, out_features=3)\n",
    "        self.dropcnn = nn.Dropout(0.25)\n",
    "        self.dropfc = nn.Dropout(0.6)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        # input image -> conv -> batchnorm -> relu -> maxpool\n",
    "        out = self.layer1(x)\n",
    "        out = self.dropcnn(out)\n",
    "        # 1st maxpool output -> conv -> batchnorm -> relu -> maxpool\n",
    "        out = self.layer2(out)\n",
    "        out = self.dropcnn(out)\n",
    "        # flatten the second maxpool output to be used as input into FCN layer\n",
    "        out = out.view(out.size(0), -1)\n",
    "\n",
    "        # Pass flattened output into FCN layers\n",
    "        out = self.fc1(out)\n",
    "        out = self.dropfc(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.dropfc(out)\n",
    "        out = self.fc3(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  ### -------------Hyperparameters------------- ###\n",
    "\n",
    "# Initialize the CNN model\n",
    "GASF_Model = CNNModel().to(device)\n",
    "\n",
    "# An easy way to give you the outline of your model\n",
    "summary(GASF_Model,  (2, 194, 194), len(strains[0]))\n",
    "\n",
    "learning_rate = 0.0005     # 0.00005\n",
    "epochs = 25                 # 40\n",
    "# batchsize = 225             # 768\n",
    "L2_reg = 0.001            # 0.00005\n",
    "\n",
    "# Define loss function and optimizer\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    GASF_Model.parameters(), \n",
    "    lr = learning_rate, \n",
    "    weight_decay=L2_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_value = np.empty(epochs)\n",
    "cost_valid_value = np.empty(epochs)\n",
    "\n",
    "for i in range(epochs):\n",
    "    t_cost = 0\n",
    "    for j, (x, y) in enumerate(tqdm(training_data, desc=f'Epoch {i+1}')):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        # print(y)\n",
    "\n",
    "        p_value = GASF_Model(x)\n",
    "\n",
    "        p_value = torch.transpose(p_value,0,1)\n",
    "        y = torch.transpose(y,0,1)\n",
    "        # print(p_value)\n",
    "        y = torch.argmax(y, dim = 1)\n",
    "        cost = loss_func(p_value, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        t_cost += cost.item()\n",
    "\n",
    "    cost_value[i] = t_cost/(j+1)\n",
    "        \n",
    "    print('========')\n",
    "    print(f'Cost{round(cost_value[i], 2)}')\n",
    "    print('========', '\\n')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        v_cost = 0\n",
    "        for run, (a, b) in enumerate(validation_data):\n",
    "            a = a.to(device)\n",
    "            b = b.to(device)\n",
    "            \n",
    "            p_value = GASF_Model(a)\n",
    "\n",
    "            p_value = torch.transpose(p_value,0,1)\n",
    "            b = torch.transpose(b,0,1)\n",
    "\n",
    "            b = torch.argmax(b, dim = 1)\n",
    "            cost_valid = loss_func(p_value, b)\n",
    "            \n",
    "            v_cost += cost_valid.item()\n",
    "            \n",
    "        cost_valid_value[i] = v_cost/(run+1)\n",
    "        \n",
    "        print('===================')\n",
    "        print(f'Validation Cost{round(cost_valid_value[i], 2)}')\n",
    "        print('===================', '\\n')\n",
    "\n",
    "\n",
    "\n",
    "# Save the model\n",
    "model_save_path='/home/dfredin/gwgasf/models/gasf_model.pth'\n",
    "os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n",
    "torch.save(GASF_Model.state_dict(), model_save_path)\n",
    "print(f'Model saved to {model_save_path}')\n",
    "\n",
    "# torch.save(GASF_Model, model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_epoch = np.linspace(1, epochs, epochs)\n",
    "plt.title('Loss value to epoch')\n",
    "plt.plot(total_epoch, cost_value, label = 'Training Set')\n",
    "plt.plot(total_epoch, cost_valid_value, label = 'Validation Set')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss Value')\n",
    "plt.legend()\n",
    "train_val_Lossplot_filename = '/home/dfredin/gwgasf/results/figures/train_val_Loss.png'\n",
    "plt.savefig(train_val_Lossplot_filename, bbox_inches = 'tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch tensor device check\n",
    "\n",
    "if device.type == 'cpu':\n",
    "    dtype = torch.FloatTensor\n",
    "elif device.type =='cuda':\n",
    "    dtype = torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(conf_matrix):\n",
    "    # Calculate precision, recall, and F1 score for the entire model\n",
    "    TP = np.sum(np.diag(conf_matrix))  # True Positives\n",
    "    FP = np.sum(np.sum(conf_matrix, axis=0) - np.diag(conf_matrix))  # False Positives\n",
    "    FN = np.sum(np.sum(conf_matrix, axis=1) - np.diag(conf_matrix))  # False Negatives\n",
    "\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    return precision, recall, f1_score\n",
    "\n",
    "def plot_confusion_matrix(data, title):\n",
    "    num_classes = 3\n",
    "    conf_matrix = torch.zeros([num_classes,num_classes]).to(device)\n",
    "    num_count = torch.zeros([num_classes]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for num, (x, y) in enumerate(tqdm(data)):\n",
    "            Real_label = y.to(device)\n",
    "\n",
    "            # Convert sofmax output to onehot\n",
    "            max_class = torch.Tensor.argmax(GASF_Model(x.to(device)), axis=1)\n",
    "            pred = F.one_hot(max_class)\n",
    "\n",
    "            # Accumlating statical value\n",
    "            conf_matrix += torch.matmul(pred.T.type(dtype), Real_label.type(dtype))\n",
    "            num_count += Real_label.sum(axis=0)\n",
    "\n",
    "        print(num_count)\n",
    "        num_count = num_count.detach().cpu().numpy().astype('float64')\n",
    "        conf_matrix = conf_matrix.detach().cpu().numpy().astype('float64')\n",
    "\n",
    "    # Normalize the confusion matrix.\n",
    "    conf_matrix /= num_count\n",
    "\n",
    "    precision, recall, f1_score = calculate_metrics(conf_matrix)\n",
    "\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F1 Score: {f1_score}')\n",
    "\n",
    "    # Labels for a 3x3 confusion matrix\n",
    "    lab = np.array([['True Positive', 'False Positive', 'False Positive'], \n",
    "                    ['False Negative', 'True Negative', 'False Positive'],\n",
    "                    ['False Negative', 'False Negative', 'True Negative']])\n",
    "\n",
    "    plt.figure()\n",
    "    color = plt.pcolormesh([conf_matrix[2], conf_matrix[1], conf_matrix[0]], cmap = 'Wistia', vmin=0, vmax=1)\n",
    "\n",
    "    # Adjust the loop for a 3x3 matrix\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            plt.text(i+.5, j+.5, \n",
    "                     f'{lab[2-j, i]}\\n{round(conf_matrix[2-j, i], 3)}', \n",
    "                     ha='center', \n",
    "                     va='center')\n",
    "\n",
    "    # Update the ticks for three classes\n",
    "    plt.xticks([.5, 1.5, 2.5], ['Glitch', 'Signal', 'Background'])\n",
    "    plt.yticks([.5, 1.5, 2.5], ['Background', 'Signal', 'Glitch'], rotation=45)\n",
    "    plt.xlabel('Predicted Value')\n",
    "    plt.ylabel('Actual Value')\n",
    "    plt.title(f'3x3 {title} Confusion Matrix')\n",
    "    plt.colorbar(color)\n",
    "    plt.savefig(f'/home/dfredin/gwgasf/results/figures/{title}_confuMatrix.png', bbox_inches = 'tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "# Call the function for each of your datasets\n",
    "plot_confusion_matrix(validation_data, 'Validation')\n",
    "plot_confusion_matrix(training_data, 'Training')\n",
    "plot_confusion_matrix(testing_data, 'Test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.undefined"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
