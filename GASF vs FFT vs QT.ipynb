{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unraveling Gravitational Ripples: Neural Network Classification\n",
    "### GASF vs FFT vs QTransform with New Data\n",
    "### **GWGASF Members:** $Daniel\\;Fredin^{1}$, $Cole\\;Welch^{1}$, $Arif\\;Chu^{1}$, $Chia-Jui\\;Chou^{2}$, $Andy\\;Chen^{2}$, & $Shih-Chieh\\;Hsu^{1}$\n",
    "#### $^{1}University\\;of\\;Washington,\\;Seattle,\\;USA$; $^{2}National\\;Yang\\;Ming\\;Chiao\\;Tung\\;University,\\;Hsinchu\\;City,\\;TW$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from pyts.image import GramianAngularField\n",
    "\n",
    "from scipy import signal\n",
    "from gwpy.timeseries import TimeSeries\n",
    "from gwpy.signal import filter_design\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from timeit import default_timer as timer\n",
    "from tqdm import tqdm, tnrange, tqdm_notebook, trange\n",
    "# from tqdm.notebook import trange\n",
    "\n",
    "# Initializes numpy and pytorch random seeds for reproducibility \n",
    "seed = 55\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "NVIDIA GeForce GTX 1650\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### -------------Load dataset------------- ###\n",
    "\n",
    "# Define the file name\n",
    "filename = 'classify_data.h5'\n",
    "\n",
    "# Open the file\n",
    "with h5py.File(filename, 'r') as file:\n",
    "    # Load the datasets\n",
    "    bbh_train = np.array(file['Training']['bbh'])\n",
    "    bbh_val = np.array(file['Validation']['bbh'])\n",
    "    glitch_train = np.array(file['Training']['glitch'])\n",
    "    glitch_val = np.array(file['Validation']['glitch'])\n",
    "\n",
    "\n",
    "# Create mock data for a 3rd classifier\n",
    "bbhGlitch_train = (bbh_train[0:12567] + glitch_train[0:12567])/2\n",
    "bbhGlitch_val = (bbh_val[0:299] + glitch_val[0:299])/2\n",
    "\n",
    "### -------------Label our data as background or signal------------- ###\n",
    "\n",
    "# # Allows us to easily apply labels to our data to denote it as signal or background for classification.\n",
    "# anomaly_class = {\n",
    "#     'Glitch': 0,\n",
    "#     'Signal': 1\n",
    "# }\n",
    "\n",
    "# Triclassifier\n",
    "anomaly_class = {\n",
    "    'Glitch': 0,\n",
    "    'Signal': 1,\n",
    "    'Glitch/Signal': 2\n",
    "}\n",
    "\n",
    "# ID our data as background or signal.\n",
    "glitch_train_ids = np.full(glitch_train.shape[0], anomaly_class['Glitch'], dtype=int)\n",
    "glitch_val_ids = np.full(glitch_val.shape[0], anomaly_class['Glitch'], dtype=int)\n",
    "\n",
    "bbh_train_ids = np.full(bbh_train.shape[0], anomaly_class['Signal'], dtype=int)\n",
    "bbh_val_ids = np.full(bbh_val.shape[0], anomaly_class['Signal'], dtype=int)\n",
    "\n",
    "bbhGlitch_train_ids = np.full(bbhGlitch_train.shape[0], anomaly_class['Glitch/Signal'], dtype=int)\n",
    "bbhGlitch_val_ids = np.full(bbhGlitch_val.shape[0], anomaly_class['Glitch/Signal'], dtype=int)\n",
    "\n",
    "### -------------Merge dataset------------- ###\n",
    "\n",
    "# Stick our background and signal data together for training and testing.\n",
    "x_train = np.concatenate((glitch_train, bbh_train, bbhGlitch_train), axis=0).transpose((0,2,1))\n",
    "y_train = np.concatenate((glitch_train_ids, bbh_train_ids, bbhGlitch_train_ids), axis=0)\n",
    "\n",
    "x_val_data = np.concatenate((glitch_val, bbh_val, bbhGlitch_val), axis=0).transpose((0,2,1))\n",
    "y_val = np.concatenate((glitch_val_ids, bbh_val_ids, bbhGlitch_val_ids), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "### -------------Shuffle dataset------------- ###\n",
    "\n",
    "# Shuffle the training data using a randomly chosen permutation. This ensures we don't encounter artifacts from background \n",
    "# and signal data being clumped together.\n",
    "idx = np.random.permutation(len(x_train))\n",
    "x_train = x_train[idx]\n",
    "y_train = y_train[idx]\n",
    "\n",
    "\n",
    "### -------------Split detector dataset------------- ###\n",
    "\n",
    "# Each 2D dataset of gravitational wave data comes from one of two detectors: 1  and 2 \n",
    "# Split the data from these two detectors since we can only pass 2D images into our CNN to train.\n",
    "x_train_dec1_raw = x_train[:,:,0]\n",
    "x_train_dec2_raw = x_train[:,:,1]\n",
    "\n",
    "x_val_dec1_raw = x_val_data[:,:,0]\n",
    "x_val_dec2_raw = x_val_data[:,:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Whitening and filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process a single item\n",
    "def process_data(raw_data):\n",
    "\n",
    "\n",
    "    # Bandpass filter for 50hz and 250hz\n",
    "    bp = filter_design.bandpass(50, 250, 4096)\n",
    "\n",
    "    ## First three harmonics of the 60 Hz AC mains power:\n",
    "    notches = [filter_design.notch(line, 4096) for line in (60, 120, 180)]\n",
    "    zpk = filter_design.concatenate_zpks(bp, *notches)\n",
    "\n",
    "\n",
    "\n",
    "    hdata = TimeSeries(raw_data)\n",
    "    hdata = hdata.whiten() \n",
    "    hdata = hdata.crop(*hdata.span.contract(1)) # The whitened timeseries data\n",
    "\n",
    "    hfilt = hdata.filter(zpk, filtfilt=True)\n",
    "    hfilt = hfilt.crop(*hfilt.span.contract(1)) # The filtered and whitened timeseries data\n",
    "\n",
    "    return hdata, hfilt\n",
    "\n",
    "\n",
    "\n",
    "### -------------Process training data------------- ###\n",
    "\n",
    "x_train_dec1_data_arr = []\n",
    "x_train_dec1_filt_arr = []\n",
    "\n",
    "x_train_dec2_data_arr = []\n",
    "x_train_dec2_filt_arr = []\n",
    "\n",
    "x_val_dec1_data_arr = []\n",
    "x_val_dec1_filt_arr = []\n",
    "\n",
    "x_val_dec2_data_arr = []\n",
    "x_val_dec2_filt_arr = []\n",
    "\n",
    "\n",
    "for raw_data in tqdm(x_train_dec1_raw):\n",
    "    hdata, hfilt = process_data(raw_data)\n",
    "    x_train_dec1_data_arr.append(hdata)\n",
    "    x_train_dec1_filt_arr.append(hfilt)\n",
    "\n",
    "x_train_dec1_data_arr = np.asarray(x_train_dec1_data_arr)\n",
    "x_train_dec1_filt_arr = np.asarray(x_train_dec1_filt_arr)\n",
    "\n",
    "\n",
    "for raw_data in tqdm(x_train_dec2_raw):\n",
    "    hdata, hfilt = process_data(raw_data)\n",
    "    x_train_dec2_data_arr.append(hdata)\n",
    "    x_train_dec2_filt_arr.append(hfilt)\n",
    "\n",
    "x_train_dec2_data_arr = np.asarray(x_train_dec2_data_arr)\n",
    "x_train_dec2_filt_arr = np.asarray(x_train_dec2_filt_arr)\n",
    "\n",
    "\n",
    "for raw_data in tqdm(x_val_dec1_raw):\n",
    "    hdata, hfilt = process_data(raw_data)\n",
    "    x_val_dec1_data_arr.append(hdata)\n",
    "    x_val_dec1_filt_arr.append(hfilt)\n",
    "\n",
    "x_val_dec1_data_arr = np.asarray(x_val_dec1_data_arr)\n",
    "x_val_dec1_filt_arr = np.asarray(x_val_dec1_filt_arr)\n",
    "\n",
    "\n",
    "for raw_data in tqdm(x_val_dec2_raw):\n",
    "    hdata, hfilt = process_data(raw_data)\n",
    "    x_val_dec2_data_arr.append(hdata)\n",
    "    x_val_dec2_filt_arr.append(hfilt)\n",
    "\n",
    "x_val_dec2_data_arr = np.asarray(x_val_dec2_data_arr)\n",
    "x_val_dec2_filt_arr = np.asarray(x_val_dec2_filt_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write filtered and whitened data to file\n",
    "filename = 'classify_data_filtered.h5'\n",
    "hf = h5py.File(filename, 'w')\n",
    "\n",
    "g1 = hf.create_group('Training/Det1')\n",
    "g1.create_dataset('whitened',data=x_train_dec1_data_arr, compression=\"gzip\", compression_opts = 5)\n",
    "g1.create_dataset('Fwhitened',data=x_train_dec1_filt_arr, compression=\"gzip\", compression_opts = 5)\n",
    "\n",
    "\n",
    "g2 = hf.create_group('Training/Det2')\n",
    "g2.create_dataset('whitened',data=x_train_dec2_data_arr, compression=\"gzip\", compression_opts = 5)\n",
    "g2.create_dataset('Fwhitened',data=x_train_dec2_filt_arr, compression=\"gzip\", compression_opts = 5)\n",
    "\n",
    "g3 = hf.create_group('Validation/Det1')\n",
    "g3.create_dataset('whitened',data=x_val_dec1_data_arr, compression=\"gzip\", compression_opts = 5)\n",
    "g3.create_dataset('Fwhitened',data=x_val_dec1_filt_arr, compression=\"gzip\", compression_opts = 5)\n",
    "\n",
    "\n",
    "g4 = hf.create_group('Validation/Det2')\n",
    "g4.create_dataset('whitened',data=x_val_dec2_data_arr, compression=\"gzip\", compression_opts = 5)\n",
    "g4.create_dataset('Fwhitened',data=x_val_dec2_filt_arr, compression=\"gzip\", compression_opts = 5)\n",
    "\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE: RESTART HERE WITHOUT HAVING TO WHITEN AND FILTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### START HERE IF YOU NEED TO RESTART WITHOUT HAVING TO WHITEN AND FILTER\n",
    "\n",
    "# y_train = np.concatenate((glitch_train_ids, bbh_train_ids), axis=0)\n",
    "# y_train = y_train[idx]\n",
    "del bbh_train, bbh_train_ids, bbh_val, bbh_val_ids, glitch_train, glitch_train_ids, glitch_val, glitch_val_ids, x_train, x_val_data\n",
    "## Read filtered data from file\n",
    "filename = 'classify_data_filtered.h5'\n",
    "\n",
    "# Open the file\n",
    "with h5py.File(filename, 'r') as file:\n",
    "    # Load the datasets\n",
    "\n",
    "    x_train_dec1_data_arr = np.array(file['Training/Det1']['whitened'])\n",
    "    x_train_dec2_data_arr = np.array(file['Training/Det2']['whitened'])\n",
    "    x_train_dec1_filt_arr = np.array(file['Training/Det1']['Fwhitened'])\n",
    "    x_train_dec2_filt_arr = np.array(file['Training/Det2']['Fwhitened'])\n",
    "\n",
    "\n",
    "    x_val_dec1_data_arr = np.array(file['Validation/Det1']['whitened'])\n",
    "    x_val_dec2_data_arr = np.array(file['Validation/Det2']['whitened'])\n",
    "    x_val_dec1_filt_arr = np.array(file['Validation/Det1']['Fwhitened'])\n",
    "    x_val_dec2_filt_arr = np.array(file['Validation/Det2']['Fwhitened'])\n",
    "    \n",
    "    file.close()\n",
    "\n",
    "\n",
    "# FILTERED DATA\n",
    "\n",
    "# x_train_dec1 = x_train_dec1_filt_arr\n",
    "# x_train_dec2 = x_train_dec2_filt_arr\n",
    "\n",
    "# y_train = y_train\n",
    "\n",
    "# x_val_dec1 = x_val_dec1_filt_arr\n",
    "# x_val_dec2 = x_val_dec2_filt_arr\n",
    "\n",
    "# del x_train_dec1_data_arr, x_train_dec2_data_arr, x_val_dec1_data_arr, x_val_dec2_data_arr\n",
    "# del x_train_dec1_filt_arr, x_train_dec2_filt_arr, x_val_dec1_filt_arr, x_val_dec2_filt_arr\n",
    "\n",
    "\n",
    "# # WHITENED DATA\n",
    "\n",
    "# x_train_dec1 = x_train_dec1_data_arr\n",
    "# x_train_dec2 = x_train_dec2_data_arr\n",
    "\n",
    "# y_train = y_train\n",
    "\n",
    "# x_val_dec1 = x_val_dec1_data_arr\n",
    "# x_val_dec2 = x_val_dec2_data_arr\n",
    "\n",
    "# del x_train_dec1_filt_arr, x_train_dec2_filt_arr, x_val_dec1_filt_arr, x_val_dec2_filt_arr\n",
    "# del x_train_dec1_data_arr, x_train_dec2_data_arr, x_val_dec1_data_arr, x_val_dec2_data_arr\n",
    "\n",
    "\n",
    "# # RAW DATA\n",
    "\n",
    "x_train_dec1 = x_train_dec1_raw\n",
    "x_train_dec2 = x_train_dec2_raw\n",
    "\n",
    "y_train = y_train\n",
    "\n",
    "x_val_dec1 = x_val_dec1_raw\n",
    "x_val_dec2 = x_val_dec2_raw\n",
    "\n",
    "del x_train_dec1_raw, x_train_dec2_raw, x_val_dec1_raw, x_val_dec2_raw\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting to ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GASF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_dec1 = x_train_dec1_raw\n",
    "x_train_dec2 = x_train_dec2_raw\n",
    "\n",
    "y_train = y_train\n",
    "\n",
    "x_val_dec1 = x_val_dec1_raw\n",
    "x_val_dec2 = x_val_dec2_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### -------------Convert dataset to GASF------------- ###\n",
    "convrt_index = 0\n",
    "# Utilize Gramian Angular Fields to transform our image from time series to images \n",
    "# so that we can apply a CNN for classification. See for an explanation: \n",
    "# Imaging Time-Series to Improve Classification and Imputation. \n",
    "# Zhiguang Wang and Tim Oates. \n",
    "# https://arxiv.org/pdf/1506.00327\n",
    "\n",
    "## NOTE: NEED TO HAVE USER INPUT FOR IMAGE SIZE??\n",
    "\n",
    "gasf = GramianAngularField(image_size=194, sample_range = (-1,1), method=\"summation\")\n",
    "# Convert training data to image format\n",
    "img_x_train_dec1 = gasf.transform(x_train_dec1)\n",
    "img_x_train_dec2 = gasf.transform(x_train_dec2)\n",
    "del x_train_dec1, x_train_dec2\n",
    "\n",
    "# Convert testing data to image format\n",
    "img_x_val_dec1 = gasf.transform(x_val_dec1)\n",
    "img_x_val_dec2 = gasf.transform(x_val_dec2)\n",
    "del x_val_dec1, x_val_dec2\n",
    "\n",
    "\n",
    "# # NOTE MAYBE DELETE XTRAIN AND XVAL TO SAVE MEMORY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stride search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (x_train_dec1[14120,:])\n",
    "series = (TimeSeries(data, sample_rate = 4096, t0=0))     #np.array --> constantQ.timeseries   \n",
    "\n",
    "ts = series\n",
    "# ts_plot = ts.plot()\n",
    "# plt.xlim(0,1)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# #         | 64x64  |  127x127  | 194x194  | 224x224   | 227x227\n",
    "# # Stride  | 0.0309 |   0.062   |  0.0945  |           | 0.1105     \n",
    "# # overlap | fft/2  | fft/1.145 | fft/1.057|           | fft/1.0425\n",
    "\n",
    "\n",
    "\n",
    "# # Spectrogram\n",
    "stride = 0.0945  \n",
    "fftlength = stride\n",
    "overlap = fftlength/1.057\n",
    "ts_spectro = ts.spectrogram2(\n",
    "    # stride=stride,\n",
    "    fftlength=fftlength,\n",
    "    overlap=overlap,\n",
    ") ** (1/2.)\n",
    "print(ts_spectro.shape)\n",
    "\n",
    "\n",
    "# spectro_plot = ts_spectro.plot(norm='log', figsize=[10,10])\n",
    "# ax = spectro_plot.gca()\n",
    "# ax.set_ylim(20, 500)\n",
    "# ax.set_xlim(0, 1)\n",
    "# ax.colorbar(label='strain ASD')\n",
    "# plt.savefig('FFT_Spectro_image.png')\n",
    "# spectro_plot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: IMPLEMENT SOME KIND OF TIMER OR STATUS TIMING\n",
    "\n",
    "\n",
    "### -------------Convert to FFT Spectrograms------------- ###\n",
    "## NOTE: TURN INTO A FUNCTION TO SIMPLIFY READABILITY\n",
    "convrt_index = 1\n",
    "\n",
    "data_list = []\n",
    "series_list = []\n",
    "fft_list = []\n",
    "\n",
    "# #         | 64x64  |  127x127  | 194x194  | 224x224   | 227x227\n",
    "# # Stride  | 0.0309 |   0.062   |  0.0945  |           | 0.1105     \n",
    "# # overlap | fft/2  | fft/1.145 | fft/1.057|           | fft/1.0425\n",
    "\n",
    "stride = 0.0945  \n",
    "fftlength = stride\n",
    "overlap = fftlength/1.057\n",
    "\n",
    "\n",
    "datas = [x_train_dec1, x_train_dec2, x_val_dec1, x_val_dec2]\n",
    "\n",
    "for d in range(len(datas)):\n",
    "    data_list = []\n",
    "    series_list = []\n",
    "    fft_list = []\n",
    "\n",
    "\n",
    "    for i in range(len(datas[d])):\n",
    "        data = (datas[d][i,:])\n",
    "        # data_list.append(data)\n",
    "        # print(datas[d].shape)\n",
    "        series = (TimeSeries(data, sample_rate = 4096, t0=0))     #np.array --> constantQ.timeseries   \n",
    "        # series_list.append(series)\n",
    "\n",
    "        series_spectro = series.spectrogram2(\n",
    "            fftlength=fftlength,\n",
    "            overlap=overlap,\n",
    "        ) ** (1/2.)\n",
    "        fft_list.append(series_spectro)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if d == 0:\n",
    "        # data_arr_x_train_dec1 = np.stack(data_list, axis = 0)\n",
    "        # series_arr_x_train_dec1 = np.asarray(series_list)\n",
    "        fft_arr_x_train_dec1 = np.asarray(fft_list)\n",
    "\n",
    "\n",
    "    elif d == 1:\n",
    "        # data_arr_x_train_dec2 = np.stack(data_list, axis = 0)\n",
    "        # series_arr_x_train_dec2 = np.asarray(series_list)\n",
    "        fft_arr_x_train_dec2 = np.asarray(fft_list)\n",
    "\n",
    "    elif d == 2:\n",
    "        # data_arr_x_test_dec1 = np.stack(data_list, axis = 0)\n",
    "        # series_arr_x_test_dec1 = np.asarray(series_list)\n",
    "        fft_arr_x_test_dec1 = np.asarray(fft_list)\n",
    "\n",
    "    else:\n",
    "        # data_arr_x_test_dec2 = np.stack(data_list, axis = 0)\n",
    "        # series_arr_x_test_dec2 = np.asarray(series_list)\n",
    "        fft_arr_x_test_dec2 = np.asarray(fft_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "del x_train_dec1, x_train_dec2\n",
    "del x_val_dec1, x_val_dec2\n",
    "\n",
    "\n",
    "img_x_train_dec1 = fft_arr_x_train_dec1\n",
    "img_x_train_dec2 = fft_arr_x_train_dec2\n",
    "img_x_val_dec1 = fft_arr_x_test_dec1\n",
    "img_x_val_dec2 = fft_arr_x_test_dec2\n",
    "\n",
    "del fft_arr_x_train_dec1, fft_arr_x_train_dec2, fft_arr_x_test_dec1, fft_arr_x_test_dec2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tres and fres search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (x_train_dec1[14120,:])\n",
    "series = (TimeSeries(data, sample_rate = 4096, t0=0))     #np.array --> constantQ.timeseries   \n",
    "\n",
    "ts = series\n",
    "ts_plot = ts.plot()\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(-7.5,7.5)\n",
    "# plt.savefig('FILTER.png')\n",
    "plt.show()\n",
    "\n",
    "# #      | 64x64  | 127x127 | 194x194 | 224x224 | 227x227\n",
    "# # tres | 0.0158 | 0.0079  | 0.00517 | 0.00448 | 0.00442\n",
    "# # fres | 16.25  | 8.2     | 5.35    | 4.62    | 4.57\n",
    "\n",
    "\n",
    "\n",
    "# # Q-Transformation\n",
    "ts_qspectro = ts.q_transform(\n",
    "    qrange=(3.3166, 108),\n",
    "    frange=(20, 1054),\n",
    "    whiten=False,\n",
    "    tres = 0.0158, \n",
    "    fres = 16.25)  \n",
    "\n",
    "q_plot = ts_qspectro.plot(figsize=[8,8])\n",
    "ax = q_plot.gca()\n",
    "ax.set_xscale('seconds')\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylim(20, 500)\n",
    "ax.set_ylabel('Frequency [Hz]')\n",
    "ax.grid(True, axis='y', which='both')\n",
    "ax.colorbar(cmap='viridis', label='Normalized energy')\n",
    "\n",
    "cbar = ax.figure.colorbar(cmap='viridis')\n",
    "cbar.mappable.set_clim(0,115)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig('QImageRAW.png')\n",
    "q_plot.show()\n",
    "print(ts_qspectro.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs[14120,:].cpu().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs[14120,0,:].cpu().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_inputs[18,0,:].cpu().numpy()\n",
    "plt.imshow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = (x_train_dec1_raw[14120,:])\n",
    "series_raw = (TimeSeries(data_raw, sample_rate = 4096, t0=0))     #np.array --> constantQ.timeseries   \n",
    "\n",
    "ts_raw = series_raw\n",
    "ts_raw_plot = ts_raw.plot()\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(-7.5,7.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (x_train_dec1_filt_arr[14120,:])\n",
    "series = (TimeSeries(data, sample_rate = 4096, t0=0))     #np.array --> constantQ.timeseries   \n",
    "\n",
    "ts = series\n",
    "ts_raw_plot = ts_raw.plot()\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(-7.5,7.5)\n",
    "plt.ylabel('Strain')\n",
    "plt.savefig(\"rawSignal.png\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "ts_plot = ts.plot()\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(-7.5,7.5)\n",
    "plt.ylabel('Strain')\n",
    "plt.savefig(\"filteredSignal.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(x_train[14120,0,:])\n",
    "plt.savefig('GASFImage.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: IMPLEMENT SOME KIND OF TIMER OR STATUS TIMING\n",
    "\n",
    "\n",
    "### -------------Convert to Q Spectrograms------------- ###\n",
    "## NOTE: TURN INTO A FUNCTION TO SIMPLIFY READABILITY\n",
    "convrt_index = 2\n",
    "\n",
    "data_list = []\n",
    "series_list = []\n",
    "Q_list = []\n",
    "\n",
    "\n",
    "datas = [x_train_dec1, x_train_dec2, x_val_dec1, x_val_dec2]\n",
    "\n",
    "for d in range(len(datas)):\n",
    "    data_list = []\n",
    "    series_list = []\n",
    "    Q_list = []\n",
    "\n",
    "\n",
    "    for i in range(len(datas[d])):\n",
    "        data = (datas[d][i,:])\n",
    "        # data_list.append(data)\n",
    "        # print(datas[d].shape)\n",
    "        series = (TimeSeries(data, sample_rate = 4096, t0=0))     #np.array --> constantQ.timeseries   \n",
    "        # series_list.append(series)\n",
    "\n",
    "        series_spectro = series.q_transform(\n",
    "        qrange=(3.3166, 108),\n",
    "        frange=(20, 1054),\n",
    "        whiten=False,\n",
    "        tres = 0.00517, \n",
    "        fres = 5.35)   \n",
    "        Q_list.append(series_spectro)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if d == 0:\n",
    "        # data_arr_x_train_dec1 = np.stack(data_list, axis = 0)\n",
    "        # series_arr_x_train_dec1 = np.asarray(series_list)\n",
    "        # Q_arr_x_train_dec1 = np.stack(Q_list, axis = 0)\n",
    "        Q_arr_x_train_dec1 = np.asarray(Q_list)\n",
    "\n",
    "\n",
    "    elif d == 1:\n",
    "        # data_arr_x_train_dec2 = np.stack(data_list, axis = 0)\n",
    "        # series_arr_x_train_dec2 = np.asarray(series_list)\n",
    "        Q_arr_x_train_dec2 = np.asarray(Q_list)\n",
    "\n",
    "    elif d == 2:\n",
    "        # data_arr_x_test_dec1 = np.stack(data_list, axis = 0)\n",
    "        # series_arr_x_test_dec1 = np.asarray(series_list)\n",
    "        Q_arr_x_test_dec1 = np.asarray(Q_list)\n",
    "\n",
    "    else:\n",
    "        # data_arr_x_test_dec2 = np.stack(data_list, axis = 0)\n",
    "        # series_arr_x_test_dec2 = np.asarray(series_list)\n",
    "        Q_arr_x_test_dec2 = np.asarray(Q_list)\n",
    "\n",
    "\n",
    "del x_train_dec1, x_train_dec2\n",
    "del x_val_dec1, x_val_dec2\n",
    "\n",
    "img_x_train_dec1 = Q_arr_x_train_dec1\n",
    "img_x_train_dec2 = Q_arr_x_train_dec2\n",
    "img_x_val_dec1 = Q_arr_x_test_dec1\n",
    "img_x_val_dec2 = Q_arr_x_test_dec2\n",
    "\n",
    "del Q_arr_x_train_dec1, Q_arr_x_train_dec2, Q_arr_x_test_dec1, Q_arr_x_test_dec2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONTINUE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Training Shape:  (34074, 2, 194, 194)\n",
      "Y Training Shape:  (34074,)\n",
      "X Testing Shape:  (4091, 2, 194, 194)\n",
      "Y Testing Shape:  (4091,)\n",
      "X Validation Shape:  (897, 2, 194, 194)\n",
      "Y Validation Shape:  (897,)\n"
     ]
    }
   ],
   "source": [
    "# Stack Detector 1 and Detector 2 image data together to unify our training and testing datasets before training.\n",
    "x_train = np.stack((img_x_train_dec1, img_x_train_dec2), axis=1)\n",
    "del img_x_train_dec1, img_x_train_dec2\n",
    "x_val = np.stack((img_x_val_dec1, img_x_val_dec2), axis=1)\n",
    "del img_x_val_dec1, img_x_val_dec2\n",
    "\n",
    "### -------------Split into training and validation datasets------------- ###\n",
    "\n",
    "## NOTE: MAYBE USER INPUT FOR SPLIT %???\n",
    "\n",
    "# Take the first 17.65% of our training features and targets as validation set\n",
    "x_test= x_train[:round((len(x_train)*0.1072))]\n",
    "y_test = y_train[:round((len(y_train)*0.1072))]\n",
    "\n",
    "# Take the remaining 82.35% of training features and targets as training set\n",
    "x_train = x_train[round((len(x_train)*0.1072)):]\n",
    "y_train = y_train[round((len(y_train)*0.1072)):]\n",
    "\n",
    "# Check the shapes of the training/validation datasets. Turns out we get about a 80%, 13%, 2% split.\n",
    "print(\"X Training Shape: \", x_train.shape)\n",
    "print(\"Y Training Shape: \", y_train.shape)\n",
    "print(\"X Testing Shape: \", x_test.shape)\n",
    "print(\"Y Testing Shape: \", y_test.shape)\n",
    "print(\"X Validation Shape: \", x_val.shape)\n",
    "print(\"Y Validation Shape: \", y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "               ## # | 64 x 64 | 127 x 127 | 194 x 194 |\n",
    "cnn1In = 2     ## # |    2    |     2     |     2     |\n",
    "cnn1Out = 64   ## # |    16   |     16    |     16    |    \n",
    "cnn1K = 6      ## # |    4    |     5     |     6     |\n",
    "cnn1S = 2      ## # |    2    |     2     |     2     |\n",
    "cnn1P = 1      ## # |    1    |     2     |     1     |\n",
    "batch1 = 64    ## # |    16   |     16    |     16    |\n",
    "max1K = 5      ## # |    4    |     2     |     5     |\n",
    "max1S = 3      ## # |    2    |     2     |     3     |\n",
    "max1P = 1      ## # |    1    |     0     |     1     |\n",
    "\n",
    "cnn2In = 64    ## # |    16   |     16    |     16    |\n",
    "cnn2Out = 128   ## # |    32   |     32    |     32    |\n",
    "cnn2K = 4      ## # |    3    |     4     |     4     |\n",
    "cnn2S = 2      ## # |    1    |     2     |     2     |\n",
    "cnn2P = 1      ## # |    1    |     1     |     1     |\n",
    "batch2 = 128    ## # |    32   |     32    |     32    |\n",
    "max2K = 2      ## # |    2    |     2     |     2     |\n",
    "max2S = 2      ## # |    2    |     2     |     2     |\n",
    "max2P = 0      ## # |    0    |     0     |     0     |\n",
    "\n",
    "### -------------194 x 194 Model Definition------------- ###\n",
    "\n",
    "class CNNModel(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(CNNModel, self).__init__()\n",
    "\n",
    "                # First convolution layer (2 channel -> 16 channels, preserve original dimension by adding padding = 2) \n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=2, out_channels=cnn1Out, kernel_size=cnn1K, stride=cnn1S, padding=cnn1P),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(batch1),\n",
    "            torch.nn.MaxPool2d(kernel_size=max1K, stride=max1S, padding=max1P)\n",
    "            )\n",
    "        \n",
    "        # Second convolution layer (16 channel -> 32 channels, preserve dimension by adding padding = 2)\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=cnn2In, out_channels=cnn2Out, kernel_size=cnn2K, stride=cnn2S, padding=cnn2P),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(batch2),\n",
    "            torch.nn.MaxPool2d(kernel_size=max2K, stride=max2S, padding=max2P)\n",
    "            )\n",
    "\n",
    "        # Fully connected layer that takes the flattened output of layer 2 (32, 8 ,8) -> (2048) and output 2 classes\n",
    "        self.fc1 = torch.nn.Linear(in_features=128*8*8, out_features=1024)\n",
    "        self.fc2 = torch.nn.Linear(in_features=1024, out_features=512)\n",
    "        self.fc3 = torch.nn.Linear(in_features=512, out_features=3)\n",
    "        self.dropcnn = torch.nn.Dropout(0.25)\n",
    "        self.dropfc = torch.nn.Dropout(0.6)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        # input image -> conv -> batchnorm -> relu -> maxpool\n",
    "        out = self.layer1(x)\n",
    "        out = self.dropcnn(out)\n",
    "        # 1st maxpool output -> conv -> batchnorm -> relu -> maxpool\n",
    "        out = self.layer2(out)\n",
    "        out = self.dropcnn(out)\n",
    "        # flatten the second maxpool output to be used as input into FCN layer\n",
    "        out = out.view(out.size(0), -1)\n",
    "\n",
    "        # Pass flattened output into FCN layers\n",
    "        out = self.fc1(out)\n",
    "        out = self.dropfc(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.dropfc(out)\n",
    "        out = self.fc3(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ### -------------227 x 227 AlexNet Model Definition------------- ###\n",
    "\n",
    "# class CNNModel(torch.nn.Module):\n",
    "    \n",
    "#     def __init__(self):\n",
    "        \n",
    "#         super(CNNModel, self).__init__()\n",
    "\n",
    "#         # First convolution layer \n",
    "#         self.layer1 = torch.nn.Sequential(\n",
    "#             torch.nn.Conv2d(in_channels=2, out_channels=24, kernel_size=11, stride=4, padding=0),\n",
    "#             torch.nn.ReLU(),\n",
    "#             torch.nn.BatchNorm2d(24),\n",
    "#             torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
    "#             )\n",
    "        \n",
    "#         # Second convolution layer \n",
    "#         self.layer2 = torch.nn.Sequential(\n",
    "#             torch.nn.Conv2d(in_channels=24, out_channels=64, kernel_size=5, stride=1, padding=2),\n",
    "#             torch.nn.ReLU(),\n",
    "#             torch.nn.BatchNorm2d(64),\n",
    "#             torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
    "#             )\n",
    "\n",
    "\n",
    "#         self.layer3 = torch.nn.Sequential(\n",
    "#             torch.nn.Conv2d(in_channels=64, out_channels=96, kernel_size=3, stride=1, padding=1),\n",
    "#             torch.nn.ReLU(),\n",
    "#             torch.nn.BatchNorm2d(96)\n",
    "#             )\n",
    "\n",
    "#         self.layer4 = torch.nn.Sequential(\n",
    "#             torch.nn.Conv2d(in_channels=96, out_channels=96, kernel_size=3, stride=1, padding=1),\n",
    "#             torch.nn.ReLU(),\n",
    "#             torch.nn.BatchNorm2d(96)\n",
    "#             )\n",
    "        \n",
    "\n",
    "#         self.layer5 = torch.nn.Sequential(\n",
    "#             torch.nn.Conv2d(in_channels=96, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "#             torch.nn.ReLU(),\n",
    "#             torch.nn.BatchNorm2d(64),\n",
    "#             torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
    "#             )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#         # Fully connected layer that takes the flattened output of layer 2 (32, 8 ,8) -> (2048) and output 2 classes\n",
    "#         self.fc1 = torch.nn.Linear(in_features=64*6*6, out_features=512)\n",
    "#         self.fc1ReLU = torch.nn.ReLU(512)\n",
    "\n",
    "#         self.fc2 = torch.nn.Linear(in_features=512, out_features=128)\n",
    "#         self.fc2ReLU = torch.nn.ReLU(128)\n",
    "\n",
    "#         self.fc3 = torch.nn.Linear(in_features=128, out_features=2)\n",
    "#         # self.fc3ReLU = torch.nn.ReLU(2)\n",
    "\n",
    "#         self.drop = torch.nn.Dropout(0.5)\n",
    "\n",
    "\n",
    "#     def forward(self, x):\n",
    "\n",
    "#         # input image -> conv -> batchnorm -> relu -> maxpool\n",
    "#         out = self.layer1(x)\n",
    "#         # 1st maxpool output -> conv -> batchnorm -> relu -> maxpool\n",
    "#         out = self.layer2(out)\n",
    "#         out = self.layer3(out)\n",
    "#         out = self.layer4(out)\n",
    "#         out = self.layer5(out)\n",
    "#         # flatten the second maxpool output to be used as input into FCN layer\n",
    "#         out = out.view(out.size(0), -1)\n",
    "\n",
    "#         # Pass flattened output into FCN layers\n",
    "#         out = self.fc1(out)\n",
    "#         out = self.fc1ReLU(out)\n",
    "#         out = self.drop(out)\n",
    "\n",
    "#         out = self.fc2(out)\n",
    "#         out = self.fc2ReLU(out)\n",
    "#         out = self.drop(out)\n",
    "\n",
    "#         out = self.fc3(out)\n",
    "        \n",
    "#         return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "  ### -------------Hyperparameters------------- ###\n",
    "\n",
    "# Initialize the CNN model\n",
    "model = CNNModel()\n",
    "learning_rate = 0.0005     # 0.00005\n",
    "epochs = 5                 # 40\n",
    "batchsize = 225             # 768\n",
    "L2_reg = 0.001            # 0.00005\n",
    "\n",
    "# Define loss function and optimizer\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay=L2_reg)\n",
    "\n",
    "if torch.cuda.is_available():                                  # Checks if the GPU is available for processing\n",
    "    model.cuda()                                               # Sends the model to the GPU for processing\n",
    "model      \n",
    "\n",
    "### -------------Creating Training Model inputs------------- ###\n",
    "\n",
    "if torch.cuda.is_available():                   # If using CUDA version of PyTorch, dataset will be processed on GPU\n",
    "\n",
    "    # # Convert train/validation/test sets into torch tensors from numpy\n",
    "    train_inputs = torch.from_numpy(x_train).float().cuda()\n",
    "    train_targets = torch.from_numpy(y_train).long().cuda()\n",
    "\n",
    "    validation_inputs = torch.from_numpy(x_val).float().cuda()\n",
    "    validation_targets = torch.from_numpy(y_val).long().cuda()\n",
    "\n",
    "    testing_inputs = torch.from_numpy(x_test).float().cuda()\n",
    "    testing_targets = torch.from_numpy(y_test).long().cuda()\n",
    "\n",
    "    # Split the training inputs/targets into mini-batches\n",
    "    train_batches_features = torch.split(train_inputs, batchsize)\n",
    "    train_batches_targets = torch.split(train_targets, batchsize)\n",
    "\n",
    "else:                                           # If not using CUDA version of PyTorch, dataset will be processed on CPU\n",
    "\n",
    "    # Convert train/validation/test sets into torch tensors from numpy\n",
    "    train_inputs = torch.from_numpy(x_train).float()\n",
    "    train_targets = torch.from_numpy(y_train).long()\n",
    "\n",
    "    validation_inputs = torch.from_numpy(x_val).float()\n",
    "    validation_targets = torch.from_numpy(y_val).long()\n",
    "\n",
    "    testing_inputs = torch.from_numpy(x_test).float()\n",
    "    testing_targets = torch.from_numpy(y_test).long()\n",
    "\n",
    "    # Split the training inputs/targets into mini-batches\n",
    "    train_batches_features = torch.split(train_inputs, batchsize)\n",
    "    train_batches_targets = torch.split(train_targets, batchsize)\n",
    "\n",
    "# length of train_batches_features = total number of mini-batches in the training set\n",
    "batch_split_num = len(train_batches_features)\n",
    "\n",
    "\n",
    "### -------------Identify tracked values------------- ###\n",
    "\n",
    "train_loss_list = []\n",
    "test_loss_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "training_accuracy_list = np.zeros((epochs,))\n",
    "testing_accuracy_list = np.zeros((epochs,))\n",
    "validation_accuracy_list = np.zeros((epochs,))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Epoch time: 532.73s Validation Accuracy: 60.31% Training loss: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model:  20%|██        | 1/5 [08:59<35:58, 539.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Epoch time: 521.08s Validation Accuracy: 63.88% Training loss: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model:  40%|████      | 2/5 [17:44<26:33, 531.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Epoch time: 519.56s Validation Accuracy: 65.55% Training loss: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model:  60%|██████    | 3/5 [26:28<17:35, 527.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Epoch time: 519.34s Validation Accuracy: 70.35% Training loss: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model:  80%|████████  | 4/5 [35:12<08:46, 526.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Epoch time: 521.86s Validation Accuracy: 69.01% Training loss: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 5/5 [43:58<00:00, 527.64s/it]\n"
     ]
    }
   ],
   "source": [
    "del x_train, y_train, x_test, y_test, x_val, y_val\n",
    "\n",
    "### -------------Training Loop------------- ###\n",
    "## NOTE: CHANGE DESC TO INCLUDE CHANGING EPOCHS\n",
    "\n",
    "for epoch in trange(epochs, desc='Training Model'):\n",
    "\n",
    "    start_time = timer() # start timer\n",
    "    # Each mini-batch number i, grab i-th training feature and target mini-batch and perform fwd/bwd pass on the network\n",
    "    \n",
    "    # for i in trange(batch_split_num, desc=f'Epoch {epoch}'):\n",
    "    for i in range(batch_split_num):\n",
    "    \n",
    "        optimizer.zero_grad()    \n",
    "        train_batch_outputs = model(train_batches_features[i])  \n",
    "        loss = loss_func(train_batch_outputs, train_batches_targets[i])\n",
    "        train_loss_list.append(loss.item())       \n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    end_time = timer() # End timer\n",
    "\n",
    "### -------------Compute Validation Accuracy------------- ###\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        validation_outputs = model(validation_inputs)\n",
    "        val_correct = (torch.argmax(validation_outputs, dim=1) == validation_targets).type(torch.FloatTensor) \n",
    "        validation_accuracy_list[epoch] = val_correct.mean()\n",
    "        \n",
    "        ## NOTE: PRINT VALIDATION LOSS TO COMPARE\n",
    "\n",
    "\n",
    "        print(\"Epoch: \"+ str(epoch),\n",
    "              \"Epoch time: \" + str(np.round(end_time - start_time, 2)) + \"s\",\n",
    "              \"Validation Accuracy: \" + str(np.round(val_correct.mean().numpy() * 100, 2)) + '%',\n",
    "              \"Training loss: \" + str(np.round(loss.item(), 2)), flush=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and reload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'MODEL\\GASF_Model.tar'\n",
    "# PATH = 'MODEL\\FFT_Model.tar'\n",
    "# PATH = 'MODEL\\Q_Model.tar'\n",
    "\n",
    "\n",
    "# torch.save({\n",
    "#             'model_state_dict': model.state_dict(),\n",
    "#             'optimizer_state_dict': optimizer.state_dict()\n",
    "#             }, PATH)\n",
    "\n",
    "\n",
    "\n",
    "model = CNNModel()\n",
    "model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay=L2_reg)\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "model.eval()\n",
    "# # - or -\n",
    "# model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize & Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: MAYBE IMPLEMENT DELETING AND CLEARING TENSOR FROM GPU BEFORE ACC CALCULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce GTX 1650\n",
      "Memory Usage:\n",
      "Allocated: 11.1 GB\n",
      "Cached:    11.2 GB\n"
     ]
    }
   ],
   "source": [
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del train_inputs\n",
    "# del train_targets\n",
    "\n",
    "del testing_inputs\n",
    "del testing_targets\n",
    "\n",
    "del validation_inputs\n",
    "del validation_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert train/validation/test sets into torch tensors from numpy\n",
    "# train_inputs = torch.from_numpy(x_train).float().cuda()\n",
    "# train_targets = torch.from_numpy(y_train).long().cuda()\n",
    "\n",
    "# validation_inputs = torch.from_numpy(x_val).float().cuda()\n",
    "# validation_targets = torch.from_numpy(y_val).long().cuda()\n",
    "\n",
    "# testing_inputs = torch.from_numpy(x_test).float().cuda()\n",
    "# testing_targets = torch.from_numpy(y_test).long().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 74.87 GiB (GPU 0; 4.00 GiB total capacity; 11.11 GiB already allocated; 0 bytes free; 11.19 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\danfr\\UW_GDrive\\GWGASF\\New_BBH_Glitch_Data\\GASF vs FFT vs QT.ipynb Cell 52\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danfr/UW_GDrive/GWGASF/New_BBH_Glitch_Data/GASF%20vs%20FFT%20vs%20QT.ipynb#Y101sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m### Generalized \u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danfr/UW_GDrive/GWGASF/New_BBH_Glitch_Data/GASF%20vs%20FFT%20vs%20QT.ipynb#Y101sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danfr/UW_GDrive/GWGASF/New_BBH_Glitch_Data/GASF%20vs%20FFT%20vs%20QT.ipynb#Y101sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# model.eval()\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danfr/UW_GDrive/GWGASF/New_BBH_Glitch_Data/GASF%20vs%20FFT%20vs%20QT.ipynb#Y101sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# torch.cuda.empty_cache()\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danfr/UW_GDrive/GWGASF/New_BBH_Glitch_Data/GASF%20vs%20FFT%20vs%20QT.ipynb#Y101sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danfr/UW_GDrive/GWGASF/New_BBH_Glitch_Data/GASF%20vs%20FFT%20vs%20QT.ipynb#Y101sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m## -------------Computing the Training accuracy------------- ###\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danfr/UW_GDrive/GWGASF/New_BBH_Glitch_Data/GASF%20vs%20FFT%20vs%20QT.ipynb#Y101sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/danfr/UW_GDrive/GWGASF/New_BBH_Glitch_Data/GASF%20vs%20FFT%20vs%20QT.ipynb#Y101sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     target_pred_test \u001b[39m=\u001b[39m model(train_inputs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danfr/UW_GDrive/GWGASF/New_BBH_Glitch_Data/GASF%20vs%20FFT%20vs%20QT.ipynb#Y101sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     train_correct \u001b[39m=\u001b[39m (torch\u001b[39m.\u001b[39margmax(target_pred_test, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m==\u001b[39m train_targets)\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mFloatTensor)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danfr/UW_GDrive/GWGASF/New_BBH_Glitch_Data/GASF%20vs%20FFT%20vs%20QT.ipynb#Y101sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     train_testing_acc \u001b[39m=\u001b[39m (train_correct\u001b[39m.\u001b[39mmean()\u001b[39m.\u001b[39mnumpy()\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\danfr\\anaconda3\\envs\\newenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\danfr\\UW_GDrive\\GWGASF\\New_BBH_Glitch_Data\\GASF vs FFT vs QT.ipynb Cell 52\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danfr/UW_GDrive/GWGASF/New_BBH_Glitch_Data/GASF%20vs%20FFT%20vs%20QT.ipynb#Y101sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danfr/UW_GDrive/GWGASF/New_BBH_Glitch_Data/GASF%20vs%20FFT%20vs%20QT.ipynb#Y101sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danfr/UW_GDrive/GWGASF/New_BBH_Glitch_Data/GASF%20vs%20FFT%20vs%20QT.ipynb#Y101sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     \u001b[39m# input image -> conv -> batchnorm -> relu -> maxpool\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/danfr/UW_GDrive/GWGASF/New_BBH_Glitch_Data/GASF%20vs%20FFT%20vs%20QT.ipynb#Y101sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer1(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danfr/UW_GDrive/GWGASF/New_BBH_Glitch_Data/GASF%20vs%20FFT%20vs%20QT.ipynb#Y101sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropcnn(out)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danfr/UW_GDrive/GWGASF/New_BBH_Glitch_Data/GASF%20vs%20FFT%20vs%20QT.ipynb#Y101sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     \u001b[39m# 1st maxpool output -> conv -> batchnorm -> relu -> maxpool\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danfr\\anaconda3\\envs\\newenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\danfr\\anaconda3\\envs\\newenv\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\danfr\\anaconda3\\envs\\newenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\danfr\\anaconda3\\envs\\newenv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\danfr\\anaconda3\\envs\\newenv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 74.87 GiB (GPU 0; 4.00 GiB total capacity; 11.11 GiB already allocated; 0 bytes free; 11.19 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "### Generalized \n",
    "\n",
    "# model.eval()\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "## -------------Computing the Training accuracy------------- ###\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    target_pred_test = model(train_inputs)\n",
    "    train_correct = (torch.argmax(target_pred_test, dim=1) == train_targets).type(torch.FloatTensor)\n",
    "    train_testing_acc = (train_correct.mean().numpy()*100)\n",
    "\n",
    "# del train_inputs\n",
    "# del train_targets\n",
    "\n",
    "# -------------Computing the testing accuracy------------- ###\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    target_pred_test = model(testing_inputs)\n",
    "    test_correct = (torch.argmax(target_pred_test, dim=1) == testing_targets).type(torch.FloatTensor)\n",
    "    test_testing_acc = (test_correct.mean().numpy()*100) \n",
    "\n",
    "# del testing_inputs\n",
    "# del testing_targets\n",
    "\n",
    "## -------------Computing the validation accuracy------------- ###\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    target_pred_test = model(validation_inputs)\n",
    "    val_correct = (torch.argmax(target_pred_test, dim=1) == validation_targets).type(torch.FloatTensor)\n",
    "    val_testing_acc = (val_correct.mean().numpy()*100)\n",
    "\n",
    "# del validation_inputs\n",
    "# del validation_targets\n",
    "\n",
    "    \n",
    "# acc = {'Testing Accuracy': [test_testing_acc],\n",
    "#            'Validation Accuracy': [val_testing_acc]}\n",
    "\n",
    "acc = {'Training Accuracy': [train_testing_acc],\n",
    "           'Testing Accuracy': [test_testing_acc],\n",
    "           'Validation Accuracy': [val_testing_acc]}\n",
    "\n",
    "results = pd.DataFrame(acc)\n",
    "\n",
    "\n",
    "## -------------Confusion Matrix------------- ###\n",
    "\n",
    "actual = validation_targets.cpu().numpy()\n",
    "predicted = (torch.argmax(model(validation_inputs), dim=1)).cpu().numpy()\n",
    "\n",
    "cm = confusion_matrix(actual, predicted)\n",
    "\n",
    "Accuracy = metrics.accuracy_score(actual, predicted)*100\n",
    "Precision = metrics.precision_score(actual, predicted)*100\n",
    "Sensitivity_recall = metrics.recall_score(actual, predicted)*100\n",
    "Specificity = metrics.recall_score(actual, predicted, pos_label=0)*100\n",
    "F1_score = metrics.f1_score(actual, predicted)*100\n",
    "\n",
    "val = {'Accuracy': [Accuracy],\n",
    "       'Precision': [Precision],\n",
    "       'Sensitivity_recall': [Sensitivity_recall],\n",
    "       'Specificity': [Specificity],\n",
    "       'F1_score': [F1_score]}\n",
    "\n",
    "val_results = pd.DataFrame(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = {'Training Accuracy': [train_testing_acc],\n",
    "           'Testing Accuracy': [test_testing_acc],\n",
    "           'Validation Accuracy': [val_testing_acc]}\n",
    "\n",
    "results = pd.DataFrame(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### -------------Plot the training loss and validation accuracy------------- ###\n",
    "\n",
    "sns.set(style = 'whitegrid', font_scale = 1)\n",
    "plt.figure(figsize = (12,10))\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams[\"font.sans-serif\"] = \"Open Sans\"\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(train_loss_list, linewidth = 3, color=\"#4b2e83\")\n",
    "plt.ylim(0,1)\n",
    "plt.ylabel(\"Training loss\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(validation_accuracy_list, linewidth = 3, color = \"#85754d\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "\n",
    "\n",
    "### NON General\n",
    "\n",
    "## GASF \n",
    "if convrt_index == 0:\n",
    "\n",
    "\n",
    "    # Plot train loss and val acc\n",
    "    plt.suptitle(\"GASF TRAINING LOSS AND VALIDATION ACCURACY\")\n",
    "    sns.despine()\n",
    "    plt.savefig(\"GASF_TrainLoss_ValAcc.png\")\n",
    "    plt.ylim()\n",
    "\n",
    "\n",
    "    # Plot Confusion matrix\n",
    "    cm_display = metrics.ConfusionMatrixDisplay(cm, \n",
    "                                                display_labels = ('Background', 'Signal'))\n",
    "    cm_display.plot(cmap=plt.cm.Blues, values_format = '')\n",
    "    plt.title('GASF Confusion Matrix for validation targets')\n",
    "    plt.grid(False)\n",
    "    plt.savefig(\"GASF_ConfMatrix.png\")\n",
    "    plt.show()\n",
    "\n",
    "    # Save results to csv\n",
    "    results.style.set_caption(\"GASF Accuracy Results\")\n",
    "    results.to_csv('GASF Accuracy Results.csv', encoding='utf-8', index=False)\n",
    "\n",
    "    val_results.style.set_caption(\"GASF Validation Results\")\n",
    "    val_results.to_csv('GASF Validation Results.csv', encoding='utf-8', index=False)\n",
    "\n",
    "\n",
    "\n",
    "## FFT \n",
    "elif convrt_index == 1:\n",
    "\n",
    "\n",
    "    # Plot train loss and val acc\n",
    "    plt.suptitle(\"FFT TRAINING LOSS AND VALIDATION ACCURACY\")\n",
    "    sns.despine()\n",
    "    plt.savefig(\"FFT_TrainLoss_ValAcc.png\")\n",
    "\n",
    "\n",
    "    # Plot Confusion matrix\n",
    "    cm_display = metrics.ConfusionMatrixDisplay(cm, \n",
    "                                                display_labels = ('Background', 'Signal'))\n",
    "    cm_display.plot(cmap=plt.cm.Blues, values_format = '')\n",
    "    plt.title('FFT Confusion Matrix for validation targets')\n",
    "    plt.grid(False)\n",
    "    plt.savefig(\"FFT_ConfMatrix.png\")\n",
    "    plt.show()\n",
    "\n",
    "    # Save results to csv\n",
    "    results.style.set_caption(\"FFT Accuracy Results\")\n",
    "    results.to_csv('FFT Accuracy Results.csv', encoding='utf-8', index=False)\n",
    "\n",
    "    val_results.style.set_caption(\"FFT Validation Results\")\n",
    "    val_results.to_csv('FFT Validation Results.csv', encoding='utf-8', index=False)\n",
    "\n",
    "\n",
    "\n",
    "## Q \n",
    "elif convrt_index == 2:\n",
    "\n",
    "\n",
    "    # Plot train loss and val acc\n",
    "    plt.suptitle(\"Q TRAINING LOSS AND VALIDATION ACCURACY\")\n",
    "    sns.despine()\n",
    "    plt.savefig(\"Q_TrainLoss_ValAcc.png\")\n",
    "\n",
    "\n",
    "    # Plot Confusion matrix\n",
    "    cm_display = metrics.ConfusionMatrixDisplay(cm, \n",
    "                                                display_labels = ('Background', 'Signal'))\n",
    "    cm_display.plot(cmap=plt.cm.Blues, values_format = '')\n",
    "    plt.title('Q Confusion Matrix for validation targets')\n",
    "    plt.grid(False)\n",
    "    plt.savefig(\"Q_ConfMatrix.png\")\n",
    "    plt.show()\n",
    "\n",
    "    # Save results to csv\n",
    "    results.style.set_caption(\"Q Accuracy Results\")\n",
    "    results.to_csv('Q Accuracy Results.csv', encoding='utf-8', index=False)\n",
    "\n",
    "    val_results.style.set_caption(\"Q Validation Results\")\n",
    "    val_results.to_csv('Q Validation Results.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs[14120,0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (train_inputs[14120,0,:].cpu().numpy())\n",
    "\n",
    "\n",
    "# ts_plot = ts.plot()\n",
    "# plt.xlim(0,1)\n",
    "# plt.show()\n",
    "\n",
    "# #      | 64x64  | 127x127 | 194x194 | 224x224 | 227x227\n",
    "# # tres | 0.0158 | 0.0079  | 0.00517 | 0.00448 | 0.00442\n",
    "# # fres | 16.25  | 8.2     | 5.35    | 4.62    | 4.57\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "\n",
    "# im = ax.imshow(data)\n",
    "\n",
    "\n",
    "ax.imshow(data)\n",
    "ax.set_xlim(0,194)\n",
    "ax.set_ylim(0,194)\n",
    "# ax.set_ylabel('Frequency [Hz]')\n",
    "# ax.grid(True, axis='y', which='both')\n",
    "ax.colorbar(cmap='viridis', label='Normalized energy')\n",
    "ax.invert_xaxis()\n",
    "ax.invert_yaxis()\n",
    "plt.savefig(\"Q_Spectro_image.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (train_inputs[14120,0,:].cpu().numpy())\n",
    "\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (train_inputs[14120,0,:].cpu().numpy())\n",
    "\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "q_plot = data.plot(figsize=[10,10])\n",
    "ax = q_plot.gca()\n",
    "ax.set_xscale('seconds')\n",
    "ax.set_yscale('log')\n",
    "# ax.set_xlim(3.5, 4.5)\n",
    "ax.set_ylim(20, 500)\n",
    "ax.set_ylabel('Frequency [Hz]')\n",
    "ax.grid(True, axis='y', which='both')\n",
    "ax.colorbar(cmap='viridis', label='Normalized energy')\n",
    "q_plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
