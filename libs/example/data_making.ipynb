{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import ml4gw\n",
    "\n",
    "import numpy as np\n",
    "from ml4gw import gw\n",
    "from ml4gw import transforms \n",
    "from ml4gw.spectral import fast_spectral_density, spectral_density\n",
    "from ml4gw.transforms import SnrRescaler, Whiten\n",
    "from ml4gw.transforms.transform import FittableSpectralTransform\n",
    "from ml4gw.distributions import LogNormal, PowerLaw\n",
    "\n",
    "from gasf.utils import h5_thang\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predefined function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masking(\n",
    "    glitch_info: dict,\n",
    "    segment_duration: float,\n",
    "    segment_start_time: float=0,\n",
    "    shift_range: float = 3, \n",
    "    pad_width: float = 1.5, # Make this default to half of the kernel width\n",
    "    sample_rate: int=4096, \n",
    "    merge_edges: bool=True\n",
    ")->dict:\n",
    "    \n",
    "    \"\"\"Provide a buffer mask the covers the glitch at the center of the kernel.\n",
    "    \n",
    "\n",
    "    Args:\n",
    "        glitch_info (dict): Glitch trigger times by each detector.\n",
    "        segment_duration (float): Duration of the background.\n",
    "        segment_start_time (float): Start time of the background. Defaults to 0.\n",
    "        kernel_width (float, optional): The time width to cover a glitch signal.\n",
    "        The unit is second. Defaults to 3.\n",
    "        pad_width (float, optional)): \n",
    "        sample_rate (int, optional): The sampling rate of the background. Defaults to 4096.\n",
    "        merge_edges (bool, optional): If true it will autometically conbine glitch masks \n",
    "        if the two kernels overlap.\n",
    "\n",
    "    Returns:\n",
    "        dict: A mask that labes the idxs that covers all glitch and edges \n",
    "        by the kernel start idx and end idx for each detectors. \n",
    "    \"\"\"\n",
    "    \n",
    "    mask_kernel = {}\n",
    "    if pad_width < shift_range/2:\n",
    "        raise AttributeError(f\"pad_width {pad_width} is shorter than half of the kernel_width {shift_range/2}\")\n",
    "    \n",
    "    half_window = int(shift_range*sample_rate/2)\n",
    "    seg_idx_count = segment_duration*sample_rate\n",
    "    \n",
    "\n",
    "    \n",
    "    for ifo, glitch_time in glitch_info.items():\n",
    "        \n",
    "        # Initialing the first digits in the active segments aline to t0 = 0_sec\n",
    "        glitch_time -= segment_start_time\n",
    "        \n",
    "        # Pop out glitch that lives in the edges\n",
    "        ### This popping may need another argument passing.\n",
    "        glitch_time = glitch_time[glitch_time > pad_width]\n",
    "        glitch_time = glitch_time[glitch_time < segment_duration - pad_width]\n",
    "        \n",
    "        glitch_counts = len(glitch_time)\n",
    "        mask_kernel[ifo] = np.zeros((glitch_counts+2, 2)).astype(\"int\")\n",
    "        \n",
    "        # Provde the pad out edges mask\n",
    "        mask_kernel[ifo][0, :] = np.array([0, pad_width*sample_rate])\n",
    "        mask_kernel[ifo][-1, :] = np.array([seg_idx_count-pad_width*sample_rate, seg_idx_count])\n",
    "        \n",
    "        # Collecting the mask by idx\n",
    "        glitch_idx = (glitch_time * 4096).astype(\"int\")\n",
    "        \n",
    "        mask_kernel[ifo][1:-1, 0] = (glitch_idx - half_window)\n",
    "        mask_kernel[ifo][1:-1, 1] = (glitch_idx + half_window)\n",
    "        \n",
    "    \n",
    "    if merge_edges:\n",
    "        \n",
    "        for ifo, mask in mask_kernel.items():\n",
    "            \n",
    "            mask_counts = mask.shape[0]\n",
    "            for i in range(mask_counts -1 ):\n",
    "                \n",
    "                if mask[i,1] > mask[i+1,0]:\n",
    "                    mask[i,1] = mask[i+1,0]\n",
    "                    \n",
    "                    \n",
    "    return mask_kernel\n",
    "\n",
    "\n",
    "def filtering_idxs(\n",
    "    mask_dict: dict,\n",
    "    *n_idxs: int,\n",
    "    full: bool=False,\n",
    "):\n",
    "    \"\"\"Find segments that \n",
    "\n",
    "    Takes in the labeles \n",
    "    Args:\n",
    "        mask_dict (dict): _description_\n",
    "        segment_dur (float): _description_\n",
    "        kernel_width (int, optional): _description_. Defaults to 2.\n",
    "        sample_rate (int, optional): _description_. Defaults to 4096.\n",
    "        shuffle (bool, optional): _description_. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    idx_dict = {}\n",
    "    for ifo, mask in mask_dict.items():\n",
    "    \n",
    "        glitch_counts = len(mask)\n",
    "\n",
    "        sampling_idx = []\n",
    "\n",
    "        for i in range(glitch_counts-1):\n",
    "            \n",
    "            # Collecting usefull segments by its idx\n",
    "            sampling_idx.append(torch.arange(mask[i,1], mask[i+1,0]))\n",
    "            \n",
    "        collected_idx = torch.cat(sampling_idx)\n",
    "        \n",
    "        \n",
    "        if full:\n",
    "            \n",
    "            idx_dict[ifo] = collected_idx\n",
    "        \n",
    "            \n",
    "        sampling_idx = torch.randint(0, len(collected_idx), n_idxs)\n",
    "\n",
    "        idx_dict[ifo] = collected_idx[sampling_idx]\n",
    "    \n",
    "    return idx_dict\n",
    "\n",
    "\n",
    "def strain_sampling(\n",
    "    strain,\n",
    "    mask: dict,\n",
    "    sample_counts,\n",
    "    sample_rate = 4096,\n",
    "    kernel_width = 2,\n",
    "):\n",
    "\n",
    "    half_kernel_width_idx = int(kernel_width * sample_rate / 2)\n",
    "    \n",
    "    sampled_strain = torch.zeros([sample_counts, len(mask), sample_rate*kernel_width])\n",
    "\n",
    "    # Cosider remove this part out of the function\n",
    "    sampling_idx = filtering_idxs(\n",
    "        mask, \n",
    "        sample_counts,\n",
    "    )\n",
    "\n",
    "    for _ , idxs in sampling_idx.items():\n",
    "        for i, idx in enumerate(idxs):\n",
    "\n",
    "            sampled_strain[i,:,:] = strain[:, idx-half_kernel_width_idx:idx+half_kernel_width_idx]\n",
    "        \n",
    "    return sampled_strain\n",
    "\n",
    "\n",
    "def glitch_sampler(\n",
    "    gltich_info,\n",
    "    strain,\n",
    "    segment_duration,\n",
    "    segment_start_time,\n",
    "    ifos,\n",
    "    sample_counts,\n",
    "    sample_rate = 4096,\n",
    "    shift_range = 0.9,\n",
    "    kernel_width = 3,\n",
    "):\n",
    "    \n",
    "    half_kernel_width_idx = int(kernel_width * sample_rate / 2)\n",
    "    \n",
    "    sampled_strain = torch.zeros([sample_counts, len(ifos), sample_rate*kernel_width])\n",
    "\n",
    "    mask_dict = masking(\n",
    "        gltich_info,\n",
    "        segment_duration=segment_duration,\n",
    "        segment_start_time=segment_start_time,\n",
    "        shift_range=shift_range,\n",
    "        pad_width=kernel_width,\n",
    "        sample_rate=sample_rate, \n",
    "        merge_edges = False\n",
    "    )\n",
    "    \n",
    "    for i, ifo in enumerate(ifos):\n",
    "        \n",
    "        # Remove the padding mask\n",
    "        mask_dict[ifo] = mask_dict[ifo][1:-1]\n",
    "        \n",
    "        glitch_count = len(mask_dict[ifo])\n",
    "        selected_glitch = np.random.randint(0, glitch_count, (sample_counts,))\n",
    "        sample_center = np.random.randint(\n",
    "            mask_dict[ifo][selected_glitch][:, 0], \n",
    "            mask_dict[ifo][selected_glitch][:, 1], \n",
    "            size=(sample_counts)\n",
    "        )\n",
    "        \n",
    "        for j in range(sample_counts):\n",
    "            \n",
    "            start_idx = sample_center[j] - half_kernel_width_idx \n",
    "            end_idx = sample_center[j] + half_kernel_width_idx\n",
    "            # print(strain[i, start_idx: end_idx].shape)\n",
    "            sampled_strain[j, i, :] = strain[i, start_idx: end_idx]\n",
    "\n",
    "    return sampled_strain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Making"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CHANNLES = 2\n",
    "\n",
    "SAMPLE_RATE = 4096\n",
    "FFTLENGTH = 2\n",
    "OVERLAP = 1\n",
    "BACKGROUND_DURATION = 4096\n",
    "KERNEL_WIDTH = 3\n",
    "WAVEFORM_DURATION = 3\n",
    "HIGHPASS = 32\n",
    "\n",
    "ITERATION = 20\n",
    "BATCH_SIZE = 320\n",
    "\n",
    "MIN_SNR = 8\n",
    "MAX_SNR = 50\n",
    "ALPHA = 3\n",
    "SNR_DISTRO = PowerLaw(MIN_SNR, MAX_SNR, ALPHA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some psudo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_strain = torch.randn(NUM_CHANNLES, SAMPLE_RATE*BACKGROUND_DURATION)\n",
    "signals = torch.randn(ITERATION*BATCH_SIZE, NUM_CHANNLES, SAMPLE_RATE*WAVEFORM_DURATION)\n",
    "\n",
    "glitch_info = {\n",
    "    \"H1\": np.sort(np.random.uniform(0+0.5, BACKGROUND_DURATION-0.5, 1000)), \n",
    "    \"L1\": np.sort(np.random.uniform(0+0.5, BACKGROUND_DURATION-0.5, 1000))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "glitch_idx_h1 = (glitch_info[\"H1\"]*SAMPLE_RATE).astype(\"int\")\n",
    "glitch_idx_l1 = (glitch_info[\"L1\"]*SAMPLE_RATE).astype(\"int\")\n",
    "\n",
    "half_glitch_idx_span = 2048\n",
    "gltich_amp = 3\n",
    "\n",
    "contaminated_strain = random_strain\n",
    "\n",
    "for pulse in glitch_idx_h1:\n",
    "    contaminated_strain[0, (pulse-half_glitch_idx_span):pulse+half_glitch_idx_span] += gltich_amp*torch.randn((2*half_glitch_idx_span))\n",
    "    \n",
    "for pulse in glitch_idx_l1:\n",
    "    contaminated_strain[1, (pulse-half_glitch_idx_span):pulse+half_glitch_idx_span] += gltich_amp*torch.randn((2*half_glitch_idx_span))\n",
    "    \n",
    "    \n",
    "del glitch_idx_h1, glitch_idx_l1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precauculate_PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is served for more detailed control \n",
    "spec_trans = FittableSpectralTransform()\n",
    "\n",
    "psds = torch.empty([NUM_CHANNLES, int((SAMPLE_RATE*KERNEL_WIDTH)/2) +1])\n",
    "\n",
    "psds[0, :] = spec_trans.normalize_psd(\n",
    "    contaminated_strain[0],\n",
    "    sample_rate=SAMPLE_RATE,\n",
    "    num_freqs=int((SAMPLE_RATE*KERNEL_WIDTH)/2) +1,\n",
    "    fftlength=FFTLENGTH,\n",
    "    overlap=OVERLAP,\n",
    ")\n",
    "\n",
    "psds[1, :] = spec_trans.normalize_psd(\n",
    "    contaminated_strain[1],\n",
    "    sample_rate=SAMPLE_RATE,\n",
    "    num_freqs=int((SAMPLE_RATE*KERNEL_WIDTH)/2) +1,\n",
    "    fftlength=FFTLENGTH,\n",
    "    overlap=OVERLAP,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling BG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Background\n",
    "\n",
    "mask_dict = masking(\n",
    "    glitch_info,\n",
    "    segment_duration=BACKGROUND_DURATION,\n",
    "    shift_range=KERNEL_WIDTH,\n",
    "    pad_width=KERNEL_WIDTH/2,\n",
    "    merge_edges = True\n",
    ")\n",
    "\n",
    "background = strain_sampling(\n",
    "    contaminated_strain,\n",
    "    mask_dict,\n",
    "    sample_counts=ITERATION*BATCH_SIZE,\n",
    "    kernel_width=KERNEL_WIDTH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glitch data\n",
    "\n",
    "glitches = glitch_sampler(\n",
    "    gltich_info=glitch_info,\n",
    "    strain = contaminated_strain,\n",
    "    segment_duration = BACKGROUND_DURATION,\n",
    "    segment_start_time = 0,\n",
    "    ifos = [\"H1\", \"L1\"],\n",
    "    sample_counts = ITERATION*BATCH_SIZE,\n",
    "    sample_rate = SAMPLE_RATE,\n",
    "    shift_range = 0.9,\n",
    "    kernel_width = 3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Injection\n",
    "\n",
    "mask_dict = masking(\n",
    "    glitch_info,\n",
    "    segment_duration=BACKGROUND_DURATION,\n",
    "    shift_range=KERNEL_WIDTH,\n",
    "    pad_width=KERNEL_WIDTH/2,\n",
    "    merge_edges = True\n",
    ")\n",
    "\n",
    "sampled_bg = strain_sampling(\n",
    "    contaminated_strain,\n",
    "    mask_dict,\n",
    "    sample_counts=ITERATION*BATCH_SIZE,\n",
    "    kernel_width=KERNEL_WIDTH\n",
    ")\n",
    "\n",
    "# Initalizing some class\n",
    "\n",
    "rescaler = SnrRescaler(\n",
    "    num_channels=NUM_CHANNLES, \n",
    "    sample_rate = SAMPLE_RATE,\n",
    "    waveform_duration = WAVEFORM_DURATION,\n",
    "    highpass = HIGHPASS,\n",
    ")\n",
    "\n",
    "rescaler.fit(\n",
    "    psds[0, :],\n",
    "    psds[1, :],\n",
    "    fftlength=FFTLENGTH,\n",
    "    overlap=OVERLAP,\n",
    "    use_pre_cauculated_psd=True\n",
    ")\n",
    "\n",
    "rescaled_signals, target_snrs, rescale_factor = rescaler.forward(\n",
    "    signals,\n",
    "    target_snrs=SNR_DISTRO(BATCH_SIZE*ITERATION)\n",
    ")\n",
    "\n",
    "injection = sampled_bg + rescaled_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "whiten_model = Whiten(\n",
    "    FFTLENGTH,\n",
    "    SAMPLE_RATE,\n",
    "    HIGHPASS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_data = whiten_model(\n",
    "    background, \n",
    "    psds\n",
    ")\n",
    "\n",
    "injected_data = whiten_model(\n",
    "    injection,\n",
    "    psds\n",
    ")\n",
    "\n",
    "glitch_data = whiten_model(\n",
    "    glitches,\n",
    "    psds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6400, 2, 4096]),\n",
       " torch.Size([6400, 2, 4096]),\n",
       " torch.Size([6400, 2, 4096]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "background_data.shape, injected_data.shape, glitch_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccsnet-train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
